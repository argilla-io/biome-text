name: text-classifier

tokenizer:
    text_cleaning:
        rules:
            - strip_spaces

features:
    words:
        embedding_dim: 300
        lowercase_tokens: true
        #weights_file: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz
    chars:
        embedding_dim: 8
        encoder:
            type: cnn
            num_filters: 50
            ngram_filter_sizes: [ 4 ]
        dropout: 0.2
        embedder:
            embedding:
                padding_index: 0
        indexer:
            character_tokenizer:
                lowercase_characters: true

encoder:
    hidden_size: 10
    num_layers: 2
    dropout: 0.5
    type: rnn

head:
    type: biome.text.modules.heads.TextClassification
    labels:
        - duplicate
        - not_duplicate