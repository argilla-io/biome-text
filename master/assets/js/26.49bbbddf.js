(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{434:function(t,e,a){"use strict";a.r(e);var n=a(27),i=Object(n.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"biome-text-hpo"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-hpo"}},[t._v("#")]),t._v(" biome.text.hpo "),a("Badge",{attrs:{text:"Module"}})],1),t._v(" "),a("div"),t._v(" "),a("p",[t._v("This module includes all components related to an HPO experiment execution.\nIt tries to allow for a simple integration with the HPO library 'Ray Tune'.")]),t._v(" "),a("div"),t._v(" "),a("pre",{staticClass:"title"},[a("h2",{attrs:{id:"tuneexperiment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tuneexperiment"}},[t._v("#")]),t._v(" TuneExperiment "),a("Badge",{attrs:{text:"Class"}})],1),t._v("\n")]),t._v(" "),a("pre",{staticClass:"language-python"},[a("code",[t._v("\n"),a("span",{staticClass:"token keyword"},[t._v("class")]),t._v(" "),a("span",{staticClass:"ident"},[t._v("TuneExperiment")]),t._v(" ("),t._v("\n    "),a("span",[t._v("pipeline_config: dict")]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("trainer_config: "),a("a",{attrs:{title:"biome.text.configuration.TrainerConfiguration",href:"configuration.html#biome.text.configuration.TrainerConfiguration"}},[t._v("TrainerConfiguration")])]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("train_dataset: "),a("a",{attrs:{title:"biome.text.dataset.Dataset",href:"dataset.html#biome.text.dataset.Dataset"}},[t._v("Dataset")])]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("valid_dataset: "),a("a",{attrs:{title:"biome.text.dataset.Dataset",href:"dataset.html#biome.text.dataset.Dataset"}},[t._v("Dataset")])]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("vocab_config: Union[str, "),a("a",{attrs:{title:"biome.text.configuration.VocabularyConfiguration",href:"configuration.html#biome.text.configuration.VocabularyConfiguration"}},[t._v("VocabularyConfiguration")]),t._v(", NoneType] = 'default'")]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("metrics: Union[NoneType, str, List[str], Dict[str, str]] = None")]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("name: Union[str, NoneType] = None")]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("trainable: Union[Callable, NoneType] = None")]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("silence: bool = False")]),a("span",[t._v(",")]),t._v("\n    "),a("span",[t._v("**kwargs")]),a("span",[t._v(",")]),t._v("\n"),a("span",[t._v(")")]),t._v("\n")]),t._v("\n")]),t._v(" "),a("p",[t._v("This class provides a trainable function and a config to conduct an HPO with "),a("code",[t._v("ray.tune.run")])]),t._v(" "),a("h2",{attrs:{id:"parameters"}},[t._v("Parameters")]),t._v(" "),a("dl",[a("dt",[a("strong",[a("code",[t._v("pipeline_config")])])]),t._v(" "),a("dd",[t._v("The pipeline configuration with its hyperparemter search spaces:\n"),a("a",{attrs:{href:"https://docs.ray.io/en/master/tune/key-concepts.html#search-spaces"}},[t._v("https://docs.ray.io/en/master/tune/key-concepts.html#search-spaces")])]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("trainer_config")])])]),t._v(" "),a("dd",[t._v("The trainer configuration with its hyperparameter search spaces")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("train_dataset")])])]),t._v(" "),a("dd",[t._v("Training dataset")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("valid_dataset")])])]),t._v(" "),a("dd",[t._v("Validation dataset")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("metrics")])])]),t._v(" "),a("dd",[t._v("Metrics to report to Tune. If this is a list, each item describes the metric key reported to PyTorch Lightning,\nand it will be reported under the same name to Tune. If this is a dict, each key will be the name reported to\nTune and the respective value will be the metric key reported to PyTorch Lightning.\nBy default (None), all metrics from Pytorch Lightning will be reported to Tune with the same name.")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("vocab_config")])])]),t._v(" "),a("dd",[t._v("A "),a("code",[t._v("VocabularyConfiguration")]),t._v(" to create/extend the pipeline's vocabulary.\nIf "),a("code",[t._v('"default"')]),t._v(" (str), we will use the default configuration "),a("code",[t._v("VocabularyConfiguration()")]),t._v(".\nIf None, we will leave the pipeline's vocabulary untouched. Default: "),a("code",[t._v('"default"')]),t._v(".")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("name")])])]),t._v(" "),a("dd",[t._v("Used as project name for the WandB logger and for the experiment name in the MLFlow logger.\nBy default we construct following string: 'HPO on %date (%time)'")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("trainable")])])]),t._v(" "),a("dd",[t._v("A custom trainable function that takes as input the "),a("code",[a("a",{attrs:{title:"biome.text.hpo.TuneExperiment.config",href:"#biome.text.hpo.TuneExperiment.config"}},[t._v("TuneExperiment.config")])]),t._v(" dict.")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("silence")])])]),t._v(" "),a("dd",[t._v("If True, silence the biome.text logger. Default: False.")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("**kwargs")])])]),t._v(" "),a("dd",[t._v("The rest of the kwargs are passed on to "),a("code",[t._v("tune.Experiment.__init__")]),t._v(".\nThey must not contain the 'name', 'run' or the 'config' key,\nsince these are provided automatically by "),a("code",[a("a",{attrs:{title:"biome.text.hpo.TuneExperiment",href:"#biome.text.hpo.TuneExperiment"}},[t._v("TuneExperiment")])]),t._v(".")])]),t._v(" "),a("h2",{attrs:{id:"attributes"}},[t._v("Attributes")]),t._v(" "),a("dl",[a("dt",[a("strong",[a("code",[t._v("trainable")])])]),t._v(" "),a("dd",[t._v("The trainable function used by ray tune")]),t._v(" "),a("dt",[a("strong",[a("code",[t._v("config")])])]),t._v(" "),a("dd",[t._v("The config dict passed on to the trainable function")])]),t._v(" "),a("h2",{attrs:{id:"examples"}},[t._v("Examples")]),t._v(" "),a("p",[t._v("A minimal usage would be:")]),t._v(" "),a("pre",[a("code",{staticClass:"language-python"},[t._v('>>> from biome.text import Dataset, TrainerConfiguration\n>>> from ray import tune\n>>> pipeline_config = {\n...     "name": "tune_experiment_example",\n...     "head": {"type": "TextClassification", "labels": ["a", "b"]},\n... }\n>>> trainer_config = TrainerConfiguration(\n...     optimizer={"type": "adam", "lr": tune.loguniform(1e-3, 1e-2)},\n...     progress_bar_refresh_rate=0\n... )\n>>> train_dataset = Dataset.from_dict({"text": ["test", "this"], "label": ["a", "b"]})\n>>> valid_dataset = Dataset.from_dict({"text": ["test", "this"], "label": ["a", "b"]})\n>>> my_exp = TuneExperiment(pipeline_config, trainer_config, train_dataset, valid_dataset, num_samples=10)\n>>> tune.run(my_exp) # doctest: +SKIP\n')])]),t._v(" "),a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"ancestors"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ancestors"}},[t._v("#")]),t._v(" Ancestors")]),t._v("\n")]),t._v(" "),a("ul",{staticClass:"hlist"},[a("li",[t._v("ray.tune.experiment.Experiment")])]),t._v(" "),a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"instance-variables"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#instance-variables"}},[t._v("#")]),t._v(" Instance variables")]),t._v("\n")]),t._v(" "),a("dl",[a("dt",{attrs:{id:"biome.text.hpo.TuneExperiment.config"}},[a("code",{staticClass:"name"},[t._v("var "),a("span",{staticClass:"ident"},[t._v("config")]),t._v(" : dict")])]),t._v(" "),a("dd",[a("p",[t._v("The config dictionary used by the "),a("code",[t._v("TuneExperiment.trainable")]),t._v(" function")])])])])}),[],!1,null,null,null);e.default=i.exports}}]);