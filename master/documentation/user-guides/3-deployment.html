<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Deployment | biome.text</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="shortcut icon" href="/biome-text/master/favicon.ico">
    <meta name="description" content="biome.text practical NLP open source library.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:image" content="https://www.recogn.ai/images/biome_og.png">
    
    <link rel="preload" href="/biome-text/master/assets/css/0.styles.26498fa5.css" as="style"><link rel="preload" href="/biome-text/master/assets/js/app.22018a0d.js" as="script"><link rel="preload" href="/biome-text/master/assets/js/4.4957ed13.js" as="script"><link rel="preload" href="/biome-text/master/assets/js/3.8baa0820.js" as="script"><link rel="preload" href="/biome-text/master/assets/js/66.05fdc5fa.js" as="script"><link rel="prefetch" href="/biome-text/master/assets/js/10.629a5f99.js"><link rel="prefetch" href="/biome-text/master/assets/js/11.7a154e19.js"><link rel="prefetch" href="/biome-text/master/assets/js/12.13cc083b.js"><link rel="prefetch" href="/biome-text/master/assets/js/13.8456f9b3.js"><link rel="prefetch" href="/biome-text/master/assets/js/14.47fb6094.js"><link rel="prefetch" href="/biome-text/master/assets/js/15.f337d446.js"><link rel="prefetch" href="/biome-text/master/assets/js/16.c32916ca.js"><link rel="prefetch" href="/biome-text/master/assets/js/17.7929c5fc.js"><link rel="prefetch" href="/biome-text/master/assets/js/18.da9659ac.js"><link rel="prefetch" href="/biome-text/master/assets/js/19.2447f479.js"><link rel="prefetch" href="/biome-text/master/assets/js/20.8d9fda21.js"><link rel="prefetch" href="/biome-text/master/assets/js/21.dcec0c08.js"><link rel="prefetch" href="/biome-text/master/assets/js/22.5a442852.js"><link rel="prefetch" href="/biome-text/master/assets/js/23.2c552ba3.js"><link rel="prefetch" href="/biome-text/master/assets/js/24.9b0142f4.js"><link rel="prefetch" href="/biome-text/master/assets/js/25.272eb7fb.js"><link rel="prefetch" href="/biome-text/master/assets/js/26.fe6023c6.js"><link rel="prefetch" href="/biome-text/master/assets/js/27.27b235b2.js"><link rel="prefetch" href="/biome-text/master/assets/js/28.5e3cccaa.js"><link rel="prefetch" href="/biome-text/master/assets/js/29.28412bba.js"><link rel="prefetch" href="/biome-text/master/assets/js/30.9a77ec30.js"><link rel="prefetch" href="/biome-text/master/assets/js/31.586bc588.js"><link rel="prefetch" href="/biome-text/master/assets/js/32.7cacae86.js"><link rel="prefetch" href="/biome-text/master/assets/js/33.3356e098.js"><link rel="prefetch" href="/biome-text/master/assets/js/34.ab105fd0.js"><link rel="prefetch" href="/biome-text/master/assets/js/35.6ebe0243.js"><link rel="prefetch" href="/biome-text/master/assets/js/36.7baf7fab.js"><link rel="prefetch" href="/biome-text/master/assets/js/37.c6cfb885.js"><link rel="prefetch" href="/biome-text/master/assets/js/38.98d9f422.js"><link rel="prefetch" href="/biome-text/master/assets/js/39.5b7fc840.js"><link rel="prefetch" href="/biome-text/master/assets/js/40.4d76ee64.js"><link rel="prefetch" href="/biome-text/master/assets/js/41.97d142f0.js"><link rel="prefetch" href="/biome-text/master/assets/js/42.d0cc289d.js"><link rel="prefetch" href="/biome-text/master/assets/js/43.68193eac.js"><link rel="prefetch" href="/biome-text/master/assets/js/44.6ddd5dd0.js"><link rel="prefetch" href="/biome-text/master/assets/js/45.f2af0899.js"><link rel="prefetch" href="/biome-text/master/assets/js/46.6bdd2a4b.js"><link rel="prefetch" href="/biome-text/master/assets/js/47.7867ffdc.js"><link rel="prefetch" href="/biome-text/master/assets/js/48.7704d097.js"><link rel="prefetch" href="/biome-text/master/assets/js/49.bd52e393.js"><link rel="prefetch" href="/biome-text/master/assets/js/5.73ece6cb.js"><link rel="prefetch" href="/biome-text/master/assets/js/50.020a7a34.js"><link rel="prefetch" href="/biome-text/master/assets/js/51.43abd9d7.js"><link rel="prefetch" href="/biome-text/master/assets/js/52.a19b02b5.js"><link rel="prefetch" href="/biome-text/master/assets/js/53.256aad2d.js"><link rel="prefetch" href="/biome-text/master/assets/js/54.27cb3cf9.js"><link rel="prefetch" href="/biome-text/master/assets/js/55.9354ee83.js"><link rel="prefetch" href="/biome-text/master/assets/js/56.0ae6d473.js"><link rel="prefetch" href="/biome-text/master/assets/js/57.7d7239a1.js"><link rel="prefetch" href="/biome-text/master/assets/js/58.7fb6b6e4.js"><link rel="prefetch" href="/biome-text/master/assets/js/59.69763eeb.js"><link rel="prefetch" href="/biome-text/master/assets/js/6.dd247cba.js"><link rel="prefetch" href="/biome-text/master/assets/js/60.f52b8667.js"><link rel="prefetch" href="/biome-text/master/assets/js/61.7bb1823f.js"><link rel="prefetch" href="/biome-text/master/assets/js/62.ec9e111d.js"><link rel="prefetch" href="/biome-text/master/assets/js/63.79ffa7af.js"><link rel="prefetch" href="/biome-text/master/assets/js/64.3b3fe7d4.js"><link rel="prefetch" href="/biome-text/master/assets/js/65.b4955888.js"><link rel="prefetch" href="/biome-text/master/assets/js/7.5737c154.js"><link rel="prefetch" href="/biome-text/master/assets/js/8.cd6cd879.js"><link rel="prefetch" href="/biome-text/master/assets/js/9.6ee71613.js"><link rel="prefetch" href="/biome-text/master/assets/js/vendors~docsearch.b3708bf9.js">
    <link rel="stylesheet" href="/biome-text/master/assets/css/0.styles.26498fa5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-348088ed><header class="navbar" data-v-348088ed><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/biome-text/master/" class="home-link router-link-active"><!----> <span class="site-name">biome<span>.text</span></span></a> <div class="links"><form id="search-form" role="search" class="algolia-search-wrapper search-box"><input id="algolia-search-input" class="search-query"></form> <nav class="nav-links can-hide"><div class="nav-item"><a href="/biome-text/master/api/" class="nav-link">
  API
</a></div><div class="nav-item"><a href="/biome-text/master/documentation/" class="nav-link router-link-active">
  Documentation
</a></div><div class="nav-item"><a href="https://github.com/recognai/biome-text" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span class="external__icon"><vp-icon color="#4A4A4A" name="blank" size="12px"></vp-icon></span></a></div><div class="nav-item"><a href="https://recogn.ai" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Recognai
  <span class="external__icon"><vp-icon color="#4A4A4A" name="blank" size="12px"></vp-icon></span></a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-348088ed></div> <aside class="sidebar" data-v-348088ed><div class="sidebar__link"><a href="/biome-text/master/"><img src="/biome-text/master/assets/img/biome.svg" class="sidebar__img"></a></div> <!----> <nav class="nav-links"><div class="nav-item"><a href="/biome-text/master/api/" class="nav-link">
  API
</a></div><div class="nav-item"><a href="/biome-text/master/documentation/" class="nav-link router-link-active">
  Documentation
</a></div><div class="nav-item"><a href="https://github.com/recognai/biome-text" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span class="external__icon"><vp-icon color="#4A4A4A" name="blank" size="12px"></vp-icon></span></a></div><div class="nav-item"><a href="https://recogn.ai" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Recognai
  <span class="external__icon"><vp-icon color="#4A4A4A" name="blank" size="12px"></vp-icon></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Get started</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/biome-text/master/documentation/" aria-current="page" class="sidebar-link">Installation</a></li><li><a href="/biome-text/master/documentation/basics.html" class="sidebar-link">The basics</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Tutorials</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/biome-text/master/documentation/tutorials/1-Training_a_text_classifier.html" class="sidebar-link">Training a short text classifier of German business names</a></li><li><a href="/biome-text/master/documentation/tutorials/2-Training_a_sequence_tagger_for_Slot_Filling.html" class="sidebar-link">Training a sequence tagger for Slot Filling</a></li><li><a href="/biome-text/master/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.html" class="sidebar-link">Hyperparameter optimization with Ray Tune</a></li><li><a href="/biome-text/master/documentation/tutorials/4-Using_Transformers_in_biome_text.html" class="sidebar-link">Using Transformers in biome.text</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>User Guides</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/biome-text/master/documentation/user-guides/1-nlp-tasks.html" class="sidebar-link">NLP Tasks</a></li><li><a href="/biome-text/master/documentation/user-guides/2-configuration.html" class="sidebar-link">Configurations</a></li><li><a href="/biome-text/master/documentation/user-guides/3-deployment.html" aria-current="page" class="active sidebar-link">Deployment</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/biome-text/master/documentation/user-guides/3-deployment.html#built-in-deployment-via-fastapi" class="sidebar-link">Built-in deployment via FastAPI</a></li><li class="sidebar-sub-header"><a href="/biome-text/master/documentation/user-guides/3-deployment.html#deployment-via-mlflow-models" class="sidebar-link">Deployment via MLFlow Models</a></li></ul></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Community</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/biome-text/master/documentation/community/1-contributing.html" class="sidebar-link">Contributing</a></li><li><a href="/biome-text/master/documentation/community/2-get_help.html" class="sidebar-link">Getting help</a></li><li><a href="/biome-text/master/documentation/community/3-developer_guides.html" class="sidebar-link">Developer guides</a></li></ul></section></li></ul> </aside> <main class="page" data-v-348088ed> <div class="theme-default-content content__default"><h1 id="deployment"><a href="#deployment" class="header-anchor">#</a> Deployment</h1> <p><em>Biome.text</em> provides an easy to use built-in tool to deploy your model
on a local machine as a REST API via <a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener noreferrer">FastAPI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.
Additionally, you can easily export your pipeline to an
<a href="https://mlflow.org/docs/latest/models.html#mlflow-models" target="_blank" rel="noopener noreferrer">MLFlow Model<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
and take advantage of all its deployment tools, like packaging the model as self-contained Docker image
with a REST API endpoint  or deploying it directly on Microsoft Azure ML or Amazon SageMaker.</p> <p></p><div class="table-of-contents"><ul><li><a href="#built-in-deployment-via-fastapi">Built-in deployment via FastAPI</a><ul><li><a href="#start-the-rest-service">Start the REST service</a></li><li><a href="#quick-tour-of-the-api">Quick-tour of the API</a></li><li><a href="#making-predictions">Making predictions</a></li></ul></li><li><a href="#deployment-via-mlflow-models">Deployment via MLFlow Models</a><ul><li><a href="#exporting-the-pipeline-to-mlflow">Exporting the pipeline to MLFlow</a></li><li><a href="#loading-and-deploying-the-mlflow-model">Loading and deploying the MLFlow Model</a></li></ul></li></ul></div><p></p> <h2 id="built-in-deployment-via-fastapi"><a href="#built-in-deployment-via-fastapi" class="header-anchor">#</a> Built-in deployment via FastAPI</h2> <p>The built-in tool uses <a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener noreferrer">FastAPI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> and an <a href="https://www.uvicorn.org/" target="_blank" rel="noopener noreferrer">Uvicorn<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> server
to expose the model as an API REST service.</p> <h3 id="start-the-rest-service"><a href="#start-the-rest-service" class="header-anchor">#</a> Start the REST service</h3> <p>For the REST service we need to save our pipeline as a <code>model.tar.gz</code> file on disk.
This can be achieved by either training our pipeline with <code>Pipeline.train()</code>, in which case the <code>model.tar.gz</code> file is part
of the training output, or by simply calling <code>Pipeline.save()</code> to serialize the pipeline in its current state.
With the <code>model.tar.gz</code> file at hand we use the <em>biome.text</em> CLI to start the API REST service from the terminal:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>biome serve path/to/output/model.tar.gz
</code></pre></div><p>If everything is correct, the Uvicorn server starts, and we should see following message in the terminal:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>INFO:     Uvicorn running on http://0.0.0.0:9999 <span class="token punctuation">(</span>Press CTRL+C to quit<span class="token punctuation">)</span>
</code></pre></div><p>At this point, everything is up and running.
We can access the documentation of the API in our browsers following this direction: <code>http://0.0.0.0:9999/docs</code></p> <h3 id="quick-tour-of-the-api"><a href="#quick-tour-of-the-api" class="header-anchor">#</a> Quick-tour of the API</h3> <p>The API docs provide an overview of the available endpoints of the REST service:</p> <ul><li>the <code>/predict</code> endpoint allows POST requests and is equivalent to the <code>Pipeline.predict()</code> method</li> <li>the <code>/config</code> endpoint returns the pipeline configuration corresponding to <code>Pipeline.config</code></li> <li>the <code>/_status</code> endpoint simply returns the status of the REST service</li></ul> <h3 id="making-predictions"><a href="#making-predictions" class="header-anchor">#</a> Making predictions</h3> <p>The best way to try out the <code>/predict</code> endpoint, is through the API docs.
If we open the <code>/predict</code> section and click on &quot;<em>Try it out</em>&quot;, the API will offer us a text field to provide our input.
The text field already provides you with a valid data scheme, and you can simply change the values of the input parameters.
For example, for a pipeline with a <code>TextClassification</code> head you could send following request body:</p> <div class="language-json extra-class"><pre class="language-json"><code><span class="token punctuation">{</span>
	<span class="token property">&quot;text&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Hello, test this input&quot;</span><span class="token punctuation">,</span>
	<span class="token property">&quot;add_tokens&quot;</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
	<span class="token property">&quot;add_attributions&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span>
<span class="token punctuation">}</span>
</code></pre></div><p>If we press <strong>Execute</strong>, we can see the POST call with <code>Curl</code> and the request URL to which we sent the request body.
We can also see the server response, with the response code, the response body and the response headers.
The response body should include the prediction corresponding to your input,
or a descriptive error message in case something went wrong.</p> <h2 id="deployment-via-mlflow-models"><a href="#deployment-via-mlflow-models" class="header-anchor">#</a> Deployment via MLFlow Models</h2> <p>Let us go through a quick example to illustrate how to deploy your <em>biome.text</em> models via MLFlow Models.</p> <h3 id="exporting-the-pipeline-to-mlflow"><a href="#exporting-the-pipeline-to-mlflow" class="header-anchor">#</a> Exporting the pipeline to MLFlow</h3> <div class="language-python extra-class"><div class="highlight-lines"><br><br><br><div class="highlighted"> </div><div class="highlighted"> </div><div class="highlighted"> </div><div class="highlighted"> </div><div class="highlighted"> </div><div class="highlighted"> </div><br><br><br><br><br></div><pre class="language-python"><code><span class="token keyword">from</span> biome<span class="token punctuation">.</span>text <span class="token keyword">import</span> Pipeline
<span class="token keyword">import</span> mlflow<span class="token punctuation">,</span> pandas

pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;to_mlflow_example&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;head&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;TextClassification&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;labels&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;b&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

model_uri <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>to_mlflow<span class="token punctuation">(</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> mlflow<span class="token punctuation">.</span>pyfunc<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_uri<span class="token punctuation">)</span>

prediction<span class="token punctuation">:</span> pandas<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>pandas<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Test this text&quot;</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>First we need to export our pipeline as MLFlow model. In this example we use a basic untrained pipeline with a
<code>TextClassification</code> head, but normally you would either load a pretrained pipeline via <code>Pipeline.from_pretrained()</code>
or train the pipeline first before exporting it.
To export the pipeline, you simply call <code>.to_mlflow()</code> that will log your pipeline as MLFlow model on a
MLFlow Tracking Server.
The tracking URI of the server, as well as the run name, and the experiment ID under which to log the model, are
configurable parameters of the method.
The returned string is the artifact URI of the MLFlow model that we can use to load or deploy our model with the
MLFlow deployment tools.</p> <h3 id="loading-and-deploying-the-mlflow-model"><a href="#loading-and-deploying-the-mlflow-model" class="header-anchor">#</a> Loading and deploying the MLFlow Model</h3> <div class="language-python extra-class"><div class="highlight-lines"><br><br><br><br><br><br><br><br><br><br><div class="highlighted"> </div><div class="highlighted"> </div><div class="highlighted"> </div><br></div><pre class="language-python"><code><span class="token keyword">from</span> biome<span class="token punctuation">.</span>text <span class="token keyword">import</span> Pipeline
<span class="token keyword">import</span> mlflow<span class="token punctuation">,</span> pandas

pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;to_mlflow_example&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;head&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;TextClassification&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;labels&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;b&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

model_uri <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>to_mlflow<span class="token punctuation">(</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> mlflow<span class="token punctuation">.</span>pyfunc<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_uri<span class="token punctuation">)</span>

prediction<span class="token punctuation">:</span> pandas<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>pandas<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Test this text&quot;</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>To use the MLFlow model for inference, we feed our model URI to the <code>mlflow.pyfunc.load_model()</code> method and call
<code>.predict()</code> on the loaded model.
MLFlow models take as input a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener noreferrer">pandas DataFrame<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
and also return their predictions as a DataFrame.</p> <p>If we wanted to serve our MLFlow model as a local REST API, we could use the MLFlow CLI command
<a href="https://www.mlflow.org/docs/latest/cli.html#mlflow-models" target="_blank" rel="noopener noreferrer"><code>mlflow models</code><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>mlflow models serve -m <span class="token operator">&lt;</span>model_uri<span class="token operator">&gt;</span>
</code></pre></div><div class="custom-block tip"><p class="custom-block-title">TIP</p> <p>Do not forget to set the <code>MLFLOW_TRACKING_URI</code> environment variable in case you use a
different tracking server location than the default <code>./mlruns</code>.</p></div> <p>An example request for the served model would be:</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">curl</span> http://127.0.0.1:5000/invocations -H <span class="token string">'Content-Type: application/json'</span> -d <span class="token string">'{
    &quot;columns&quot;: [&quot;text&quot;],
    &quot;data&quot;: [&quot;test this input&quot;, &quot;and this as well&quot;]
}'</span>
</code></pre></div><p>For more details about how to exploit all MLFlow Model features,
like deploying them on Microsoft Azure ML or Amazon SageMaker, please refer to their
<a href="https://www.mlflow.org/docs/latest/models.html#built-in-deployment-tools" target="_blank" rel="noopener noreferrer">documentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="page-nav__button prev"><a href="/biome-text/master/documentation/user-guides/2-configuration.html" class="prev"><span class="page-nav__button__icon"><vp-icon color="#4A4A4A" name="chev-left" size="18px"></vp-icon></span> <span class="page-nav__button__text">
          Configurations
        </span></a></span> <span class="page-nav__button next"><a href="/biome-text/master/documentation/community/1-contributing.html"><span class="page-nav__button__text">
          Contributing
        </span> <span class="page-nav__button__icon"><vp-icon color="#4A4A4A" name="chev-right" size="18px"></vp-icon></span></a></span></p></div> <footer class="footer" data-v-348088ed><div data-v-348088ed>
          Maintained by
          <a href="https://www.recogn.ai/" target="_blank" data-v-348088ed><img width="70px" src="/biome-text/master/assets/img/recognai.png" class="footer__img" data-v-348088ed></a></div></footer> </main></div><div class="global-ui"><!----></div></div>
    <script src="/biome-text/master/assets/js/app.22018a0d.js" defer></script><script src="/biome-text/master/assets/js/4.4957ed13.js" defer></script><script src="/biome-text/master/assets/js/3.8baa0820.js" defer></script><script src="/biome-text/master/assets/js/66.05fdc5fa.js" defer></script>
  </body>
</html>
