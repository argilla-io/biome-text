{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization with Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://www.recogn.ai/biome-text/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.html\"><img class=\"icon\" src=\"https://www.recogn.ai/biome-text/assets/img/biome-isotype.svg\" width=24 /></a>\n",
    "[View on recogn.ai](https://www.recogn.ai/biome-text/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.html)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/recognai/biome-text/blob/master/docs/docs/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.ipynb\"><img class=\"icon\" src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" width=24 /></a>\n",
    "[Run in Google Colab](https://colab.research.google.com/github/recognai/biome-text/blob/master/docs/docs/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.ipynb)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://github.com/recognai/biome-text/blob/master/docs/docs/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.ipynb\"><img class=\"icon\" src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=24 /></a>\n",
    "[View source on GitHub](https://github.com/recognai/biome-text/blob/master/docs/docs/documentation/tutorials/3-Hyperparameter_optimization_with_Ray_Tune.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will optimize the hyperparameters of the short-text classifier from [this tutorial](https://www.recogn.ai/biome-text/documentation/tutorials/1-Training_a_text_classifier.html).\n",
    "We recommend to have a look at it first before going through the following tutorial.\n",
    "For the Hyper-Parameter Optimization (HPO) we rely on the awesome [Ray Tune library](https://docs.ray.io/en/latest/tune.html#tune-index) that is **not** a dependency of *biome.text* and has to be installed additionally.\n",
    "\n",
    "For a short introduction to HPO with Ray Tune you can have a look at this nice [talk](https://www.youtube.com/watch?v=VX7HvEoMrsA) by Richard Liaw. \n",
    "We will follow his terminology and use the term *trial* to refer to a training run of one set of hyperparameters. \n",
    "\n",
    "When running this tutorial in Google Colab, make sure to install *biome.text* and *ray tune* first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/recognai/biome-text.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore warnings and don't forget to restart your runtime afterwards (*Runtime -> Restart runtime*).\n",
    "\n",
    "If you want to log your runs with [WandB](https://wandb.ai), don't forget to install its client and log in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: tip Note\n",
    "\n",
    "In this tutorial we will use a GPU by default.\n",
    "So when running this tutorial in Google Colab, make sure that you request one (*Edit -> Notebook settings*).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First let's import all the stuff we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from biome.text.data import DataSource\n",
    "from biome.text import Pipeline\n",
    "from biome.text.configuration import VocabularyConfiguration, WordFeatures, TrainerConfiguration\n",
    "from biome.text.loggers import BaseTrainLogger\n",
    "from biome.text.hpo import HpoParams, HpoExperiment\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we will download the training and validation data to our local machine. \n",
    "This will save us some time in the long run, since we will perform the hyperparameter search on our local machine and access the data frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://biome-tutorials-data.s3-eu-west-1.amazonaws.com/text_classifier/business.cat.train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://biome-tutorials-data.s3-eu-west-1.amazonaws.com/text_classifier/business.cat.valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store the absolute path of the data to use them later on when creating our `DataSource`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.abspath(\"business.cat.train.csv\")\n",
    "valid_path = os.path.abspath(\"business.cat.valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be more efficient and speed things up, we will create the vocabulary beforehand and reuse it in every trial.\n",
    "For this we have to define a `Pipeline` first and create the vocabulary from our `DataSource`.\n",
    "\n",
    "Let's start with defining the configuration of our pipeline (for details see the [base tutorial](https://www.recogn.ai/biome-text/documentation/tutorials/1-Training_a_text_classifier.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = DataSource(train_path).to_dataframe().label.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dict = {\n",
    "    \"name\": \"german_business_names\",\n",
    "    \"tokenizer\": {\n",
    "        \"text_cleaning\": {\n",
    "            \"rules\": [\"strip_spaces\"]\n",
    "        }\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"word\": {\n",
    "            \"embedding_dim\": 64,\n",
    "            \"lowercase_tokens\": True,\n",
    "        },\n",
    "        \"char\": {\n",
    "            \"embedding_dim\": 32,\n",
    "            \"lowercase_characters\": True,\n",
    "            \"encoder\": {\n",
    "                \"type\": \"gru\",\n",
    "                \"num_layers\": 1,\n",
    "                \"hidden_size\": 32,\n",
    "                \"bidirectional\": True,\n",
    "            },\n",
    "            \"dropout\": 0.1,\n",
    "        },\n",
    "    },\n",
    "    \"head\": {\n",
    "        \"type\": \"TextClassification\",\n",
    "        \"labels\": list(labels.value_counts().index),\n",
    "        \"pooler\": {\n",
    "            \"type\": \"gru\",\n",
    "            \"num_layers\": 1,\n",
    "            \"hidden_size\": 32,\n",
    "            \"bidirectional\": True,\n",
    "        },\n",
    "        \"feedforward\": {\n",
    "            \"num_layers\": 1,\n",
    "            \"hidden_dims\": [32],\n",
    "            \"activations\": [\"relu\"],\n",
    "            \"dropout\": [0.0],\n",
    "        },\n",
    "    },       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this configuration dictionary to create our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline.from_config(pipeline_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to define the vocabulary configuration and create our vocabulary.\n",
    "\n",
    "\n",
    "::: tip Note\n",
    "\n",
    "If you want to optimize the vocabulary configuration in the hyperparameter search (for example, the `min_count` argument), you have to move the vocabulary creation to the `trainable` function below. That is, in each trial the vocabulary will be created anew.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config = VocabularyConfiguration(sources=[DataSource(train_path)], min_count={WordFeatures.namespace: 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.create_vocabulary(vocab_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search with a trial scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a random hyperparameter search (as well as a grid search) we simply have to replace the parameters we want to optimize with methods from the [Random Distributions API](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html#random-distributions-api) and the [Grid Search API](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html#grid-search-api), respectively.\n",
    "For a complete description of both APIs and how they interplay with each other, see the corresponding section in the [Ray Tune docs](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html). \n",
    "\n",
    "In our case we will tune 9 parameters:\n",
    "- the output dimensions of our `word` and `char` features\n",
    "- the dropout of our `char` feature\n",
    "- the architecture of our pooler (*GRU* versus *LSTM*)\n",
    "- number of layers and hidden size of our pooler, as well as if it should be bidirectional\n",
    "- hidden dimension of our feed forward network\n",
    "- and the learning rate\n",
    "\n",
    "For most of the parameters we will provide discrete values from which Tune will sample randomly, while for the dropout and learning rate we will provide a continuous linear and logarithmic range, respectively.\n",
    "Since we want to directly compare the outcome of the optimization with the base configuration of the [underlying tutorial](https://www.recogn.ai/biome-text/documentation/tutorials/1-Training_a_text_classifier.html), we will fix the number of epochs to 3.\n",
    "\n",
    "Not all of the parameters above are worth tuning, but we want to stress the flexibility that *Ray Tune* and *biome.text* offers you.\n",
    "\n",
    "::: tip Tip\n",
    "\n",
    "Keep in mind that the learning rate \"*is often the single most important hyper-parameter and one should always make sure that it has been tuned (up to approximately a factor of 2). ... If there is only time to optimize one hyper-parameter and one uses stochastic gradient descent, then this is the hyper-parameter that is worth tuning.*\" ([Yoshua Bengio](https://arxiv.org/abs/1206.5533)).\n",
    "\n",
    ":::\n",
    "\n",
    "We will use the `HpoParams` class to define our tunable parameters and to configure our trainer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_params = HpoParams(\n",
    "    pipeline={\n",
    "        \"features\": {\n",
    "            \"word\": {\n",
    "                \"embedding_dim\": tune.choice([32, 64])\n",
    "            },\n",
    "            \"char\": {\n",
    "                \"encoder\": {\n",
    "                    \"hidden_size\": tune.choice([32, 64])\n",
    "                },\n",
    "                \"dropout\": tune.uniform(0, 0.5)\n",
    "            }\n",
    "        },\n",
    "        \"head\": {\n",
    "            \"pooler\": {\n",
    "                \"type\": tune.choice([\"gru\", \"lstm\"]),\n",
    "                \"num_layers\": tune.choice([1, 2]),\n",
    "                \"hidden_size\": tune.choice([32, 64]),\n",
    "                \"bidirectional\": tune.choice([True, False])\n",
    "            },\n",
    "            \"feedforward\": {\n",
    "                \"hidden_dims\": [tune.choice([32, 64])],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    trainer={\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": tune.loguniform(0.001, 0.01),\n",
    "        },\n",
    "        \"num_epochs\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: tip Note\n",
    "\n",
    "By default we will use a GPU if available.\n",
    "If you do not want to use your GPU, just specify `\"cuda_device\": -1` in the trainer section of the dictionary above.\n",
    "\n",
    ":::\n",
    "\n",
    "We then create an `HpoExperiment` with a name that will mainly be used as project name for the MLFlow and WandB logger.\n",
    "We also tell it to share the vocab among the trials by setting `shared_vocab` to true, and to sample 50 times from the hyperparameter space by setting `num_samples` to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_experiment = HpoExperiment(\n",
    "    name=\"my_first_hpo_experiment\",\n",
    "    pipeline=pl,\n",
    "    train=train_path,\n",
    "    validation=valid_path,\n",
    "    hpo_params=hpo_params,\n",
    "    shared_vocab=True,\n",
    "    num_samples=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will perform a random search together with the [Asynchronous Successive Halving Algorithm (ASHA)](https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/) to schedule our trials.\n",
    "The Ray Tune developers advocate this scheduler as a good starting point for its aggressive termination of low-performing trials.\n",
    "\n",
    "To create an instance of the `ASHAScheduler` we have to specify the decisive metric for terminating low-performing trials and the mode of this metric (is the objective to *minimize* the metric, `min`, or to *maximize* it, `max`).\n",
    "For a complete description of the configurations, see the [ASHAScheduler docs](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#asha-tune-schedulers-ashascheduler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asha = tune.schedulers.ASHAScheduler(metric=\"validation_loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following the progress with tensorboard (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray Tune automatically logs its results with [TensorBoard](https://www.tensorflow.org/tensorboard/).\n",
    "We can take advantage of this and launch a TensorBoard instance before starting the hyperparameter search to follow its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./runs/tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of TensorBoard with Ray Tune](./img/hpo_tensorboard.png)\n",
    "*Screenshot of TensorBoard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything ready to start our hyperparameter search with the `tune.run()` method.\n",
    "\n",
    "The number of trials our search will go through depends on the `num_samples` parameter.\n",
    "In our case, a random search, it equals the number of trials, whereas in the case of a grid search the total number of trials is `num_samples` times the grid configurations (see the [Tune docs](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html) for illustrative examples).\n",
    "\n",
    "The number of parallel running trials depends on your `resources_per_trial` configuration and your local resources.\n",
    "The default value is `{\"cpu\": 1, \"gpu\": 0}` and results, for example, in 8 parallel running trials on a machine with 8 CPUs.\n",
    "You can also use fractional values. To share a GPU between 2 trials, for example, pass on `{\"gpu\": 0.5}`. \n",
    "\n",
    "The `local_dir` parameter defines the output directory of the HPO results and will also contain the training results of each trial (that is the model weights and metrics).\n",
    "\n",
    "::: tip Note\n",
    "\n",
    "Keep in mind: to run your HPO on GPUs, you have to specify them in the `TrainerConfiguration` in the `trainable` function, as well as in the `resources_per_trial` parameter when calling `tune.run()`.\n",
    "If you do not want to use a GPU, just set the value to 0 `{\"cpu\": 1, \"gpu\": 0}`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    hpo_experiment.as_tune_experiment(),  \n",
    "    scheduler=asha, \n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 0.5},\n",
    "    progress_reporter=tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *analysis* object returned by `tune.run()` can be accessed through a *pandas DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.dataframe().sort_values(\"validation_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of the analysis dataframe](./img/analysis_df.png)\n",
    "*Screenshot of the analysis dataframe*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event though with 50 trials we visit just a small space of our possible configurations, we should have achieved an accuracy of ~0.94, an increase of roughly 3 points compared to the original configuration of the [base tutorial](https://www.recogn.ai/biome-text/documentation/tutorials/1-Training_a_text_classifier.html).\n",
    "\n",
    "In a real-life example, though, you probably should increase the number of epochs, since the validation loss in general seems to be decreasing further.\n",
    "\n",
    "A next step could be to fix some of the tuned parameters to the preferred value, and tune other parameters further or limit their value space.\n",
    "\n",
    "::: tip Tip\n",
    "\n",
    "To obtain insights about the importance and tendencies of each hyperparameter for the model, we recommend using TensorBoard's *HPARAM* section and follow Richard Liaw's suggestions at the end of his [talk](https://www.youtube.com/watch?v=VX7HvEoMrsA).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *analysis* object also provides some convenient methods to obtain the best performing configuration, as well as the `logdir` where the results of the trial are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = analysis.get_best_config(metric=\"validation_loss\", mode=\"min\")\n",
    "best_logdir = analysis.get_best_logdir(metric=\"validation_loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `best_logdir` to create a pipeline with the best performing model and start making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = os.path.join(best_logdir, \"output\", \"model.tar.gz\")\n",
    "pl_trained = Pipeline.from_pretrained(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_trained.predict(text=\"Autohaus Recognai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use *biome.text*'s explore UI to evaluate the performance of our model in more detail. \n",
    "\n",
    "::: warning Warning\n",
    "\n",
    "For the UI to work you need a running [Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html) instance.\n",
    "We recommend installing [Elasticsearch with docker](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/docker.html#docker-cli-run-dev-mode).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biome.text import explore\n",
    "\n",
    "explore.create(pl_trained, DataSource(valid_path), explain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of the biome.text explore UI](./img/text_classifier_explore_screenshot.png)\n",
    "*Screenshot of the biome.text explore UI*\n",
    "\n",
    "::: tip Note\n",
    "\n",
    "For an unbiased evaluation of the model you should use a test dataset that was not used during the HPO!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Custom HPO with ray tune\n",
    "\n",
    "As seen in this tutorial, *biome.text* provides you some convenient tools to easily perform HPO in a few steps.\n",
    "To take advantage of all the ray tune features, you can also define your own trainable function and follow ray tune's [function API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#tune-function-api).\n",
    "\n",
    "Below we give a minimal example of such an approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of features in ray tune require the trials to report some metrics during their trainings, such as trial schedulers that adaptively allocate resources as the ASHA scheduler used above.\n",
    "For the reporting we can use the abstract `biome.text.loggers.BaseTrainLogger` class, that allows to make callbacks after each epoch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneReporter(BaseTrainLogger):\n",
    "    def log_epoch_metrics(self, epoch, metrics):\n",
    "        tune.report(\n",
    "            validation_loss=metrics[\"validation_loss\"], \n",
    "            validation_accuracy=metrics[\"validation_accuracy\"]\n",
    "        )\n",
    "        \n",
    "tune_reporter = TuneReport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the [function-based Trainable API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#tune-function-api), we now have to define a `trainable` function that takes as input a configuration dictionary and executes a training run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config):\n",
    "    pl = Pipeline.from_config(config[\"pipeline\"])\n",
    "    trainer_config = TrainerConfiguration(**config[\"trainer\"])\n",
    "    \n",
    "    train_ds = DataSource(train_path)\n",
    "    valid_ds = DataSource(valid_path)\n",
    "    \n",
    "    pl.create_vocabulary(VocabularyConfiguration(sources=[train_ds]))\n",
    "    \n",
    "    pl.train(\n",
    "        output=\"output\",\n",
    "        training=train_ds,\n",
    "        validation=valid_ds,\n",
    "        trainer=trainer_config,\n",
    "        loggers=[tune_report],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Pipeline.train()` method above we added our `tune_reporter` instance to the loggers in order to report the validation loss and accuracy back to tune.\n",
    "The `config` dictionary, where we define the pipeline, trainer and the hyperparameters, could look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"pipeline\": {\n",
    "        \"name\": \"german_business_names\",\n",
    "        \"tokenizer\": {\n",
    "            \"text_cleaning\": {\n",
    "                \"rules\": [\"strip_spaces\"]\n",
    "            }\n",
    "        },\n",
    "        \"features\": {\n",
    "            \"word\": {\n",
    "                \"embedding_dim\": tune.choice([32, 64]),\n",
    "                \"lowercase_tokens\": True,\n",
    "            },\n",
    "        },\n",
    "        \"head\": {\n",
    "            \"type\": \"TextClassification\",\n",
    "            \"labels\": list(labels.value_counts().index),\n",
    "            \"pooler\": {\n",
    "                \"type\": tune.choice([\"gru\", \"lstm\"]),\n",
    "                \"num_layers\": tune.choice([1, 2]),\n",
    "                \"hidden_size\": tune.choice([32,64]),\n",
    "                \"bidirectional\": tune.choice([True, False]),\n",
    "            },\n",
    "        },       \n",
    "    }, \n",
    "    \"trainer\": {\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": tune.loguniform(0.001, 0.01),\n",
    "        },\n",
    "        \"num_epochs\": 3,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trainable function at hand we can now call the `tune.run` method to start our HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    trainable, \n",
    "    config=configs, \n",
    "    num_samples=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an advanced example with checkpointing, you can have a look at the colab notebook [*Population Based Training with biome.text*](https://colab.research.google.com/drive/1vmt3D_2kq6VxE2-nlwsZl0YrN3nAhHp0?usp=sharing)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
