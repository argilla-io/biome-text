(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{400:function(e,t,a){"use strict";a.r(t);var s=a(18),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"biome-text-api-new-featurizer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-api-new-featurizer"}},[e._v("#")]),e._v(" biome.text.api_new.featurizer "),a("Badge",{attrs:{text:"Module"}})],1),e._v(" "),a("dl",[a("h2",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer"}},[e._v("InputFeaturizer "),a("Badge",{attrs:{text:"Class"}})],1),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[e._v("    "),a("code",[e._v("\n"),a("span",{staticClass:"token keyword"},[e._v("class")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("InputFeaturizer")]),e._v(" ("),e._v("\n    "),a("span",[e._v("words: Union[Dict[str, Any], NoneType] = None")]),a("span",[e._v(",")]),e._v("\n    "),a("span",[e._v("chars: Union[Dict[str, Any], NoneType] = None")]),a("span",[e._v(",")]),e._v("\n    "),a("span",[e._v("**kwargs: Dict[str, Dict[str, Any]]")]),a("span",[e._v(",")]),e._v("\n"),a("span",[e._v(")")]),e._v("\n    ")])])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"},[a("p",[e._v("The input features class. Centralize the token_indexers and embedder configurations, since are very coupled.")]),e._v(" "),a("p",[e._v("This class define two input features: words and chars for embeddings at word and character level. In those cases,\nthe required configuration is specified in "),a("code",[e._v("_WordFeaturesSpecs")]),e._v(" and "),a("code",[e._v("_CharacterFeaturesSpec")]),e._v(" respectively")]),e._v(" "),a("p",[e._v("You can provide addittional features by manually specify "),a("code",[e._v("indexer")]),e._v(" and "),a("code",[e._v("embedder")]),e._v(" configurations.")])]),e._v(" "),a("h3",[e._v("Class variables")]),e._v(" "),a("dl",[a("dt",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.WORDS"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("WORDS")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"})]),e._v(" "),a("dt",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.CHARS"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("CHARS")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"})])]),e._v(" "),a("dl",[a("h3",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.from_params"}},[e._v("from_params "),a("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[a("code",[e._v("\n"),a("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("from_params")]),e._v("("),a("span",[e._v("params: allennlp.common.params.Params) -> "),a("a",{attrs:{title:"biome.text.api_new.featurizer.InputFeaturizer",href:"#biome.text.api_new.featurizer.InputFeaturizer"}},[e._v("InputFeaturizer")])]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"},[a("p",[e._v("Load a input featurizer from allennlp params")])])])]),e._v(" "),a("h3",[e._v("Instance variables")]),e._v(" "),a("dl",[a("dt",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.config"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("config")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"},[a("p",[e._v("The data module configuration")])])]),e._v(" "),a("dt",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.feature_keys"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("feature_keys")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"},[a("p",[e._v('The configured feature names ("words", "chars", …)')])])])]),e._v(" "),a("dl",[a("h3",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.build_features"}},[e._v("build_features "),a("Badge",{attrs:{text:"Method"}})],1),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[a("code",[e._v("\n"),a("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("build_features")]),e._v("("),a("span",[e._v("self) -> Dict[str, allennlp.data.token_indexers.token_indexer.TokenIndexer]")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"},[a("p",[e._v("Build configured token indexers features in terms of allennlp token indexers.")]),e._v(" "),a("p",[e._v("The result configuration is inmutable")])])]),e._v(" "),a("h3",{attrs:{id:"biome.text.api_new.featurizer.InputFeaturizer.build_embedder"}},[e._v("build_embedder "),a("Badge",{attrs:{text:"Method"}})],1),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[a("code",[e._v("\n"),a("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("build_embedder")]),e._v(" ("),e._v("\n   self,\n   vocab: allennlp.data.vocabulary.Vocabulary,\n)  -> allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder\n")]),e._v("\n        ")])])]),e._v(" "),a("dd",[a("div",{staticClass:"desc"},[a("p",[e._v("Build the allennlp "),a("code",[e._v("TextFieldEmbedder")]),e._v(" from configured embedding features")])])])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);