(window.webpackJsonp=window.webpackJsonp||[]).push([[73],{411:function(e,s,t){"use strict";t.r(s);var i=t(26),n=Object(i.a)({},(function(){var e=this,s=e.$createElement,t=e._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"biome-text-models-sequence-classifier"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-models-sequence-classifier"}},[e._v("#")]),e._v(" biome.text.models.sequence_classifier "),t("Badge",{attrs:{text:"Module"}})],1),e._v(" "),t("dl",[t("h2",{attrs:{id:"biome.text.models.sequence_classifier.SequenceClassifier"}},[e._v("SequenceClassifier "),t("Badge",{attrs:{text:"Class"}})],1),e._v(" "),t("dt",[t("div",{staticClass:"language-python extra-class"},[t("pre",{staticClass:"language-python"},[e._v("    "),t("code",[e._v("\n"),t("span",{staticClass:"token keyword"},[e._v("class")]),e._v(" "),t("span",{staticClass:"ident"},[e._v("SequenceClassifier")]),e._v(" ("),e._v("\n    "),t("span",[e._v("vocab: allennlp.data.vocabulary.Vocabulary")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("text_field_embedder: allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("seq2vec_encoder: allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("seq2seq_encoder: Union[allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("multifield_seq2seq_encoder: Union[allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("multifield_seq2vec_encoder: Union[allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("feed_forward: Union[allennlp.modules.feedforward.FeedForward, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("dropout: Union[float, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("multifield_dropout: Union[float, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("initializer: Union[allennlp.nn.initializers.InitializerApplicator, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("regularizer: Union[allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("accuracy: Union[allennlp.training.metrics.categorical_accuracy.CategoricalAccuracy, NoneType] = None")]),t("span",[e._v(",")]),e._v("\n    "),t("span",[e._v("loss_weights: Dict[str, float] = None")]),t("span",[e._v(",")]),e._v("\n"),t("span",[e._v(")")]),e._v("\n    ")])])])]),e._v(" "),t("dd",[t("div",{staticClass:"desc"},[t("p",[e._v("In the most simple form this "),t("code",[e._v("BaseModelClassifier")]),e._v(" encodes a sequence with a "),t("code",[e._v("Seq2VecEncoder")]),e._v(", then\npredicts a label for the sequence.")]),e._v(" "),t("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),t("dl",[t("dt",[t("strong",[t("code",[e._v("vocab")])])]),e._v(" "),t("dd",[e._v("A Vocabulary, required in order to compute sizes for input/output projections\nand passed on to the :class:"),t("code",[e._v("~allennlp.models.model.Model")]),e._v(" class.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("text_field_embedder")])])]),e._v(" "),t("dd",[e._v("Used to embed the input text into a "),t("code",[e._v("TextField")])]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("seq2seq_encoder")])])]),e._v(" "),t("dd",[e._v("Optional Seq2Seq encoder layer for the input text.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("seq2vec_encoder")])])]),e._v(" "),t("dd",[e._v("Required Seq2Vec encoder layer. If "),t("code",[e._v("seq2seq_encoder")]),e._v(" is provided, this encoder\nwill pool its output. Otherwise, this encoder will operate directly on the output\nof the "),t("code",[e._v("text_field_embedder")]),e._v(".")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("dropout")])])]),e._v(" "),t("dd",[e._v("Dropout percentage to use on the output of the Seq2VecEncoder")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("multifield_seq2seq_encoder")])])]),e._v(" "),t("dd",[e._v("Optional Seq2Seq encoder layer for the encoded fields.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("multifield_seq2vec_encoder")])])]),e._v(" "),t("dd",[e._v("If we use "),t("code",[e._v("ListField")]),e._v("s, this Seq2Vec encoder is required.\nIf "),t("code",[e._v("multifield_seq2seq_encoder")]),e._v(" is provided, this encoder will pool its output.\nOtherwise, this encoder will operate directly on the output of the "),t("code",[e._v("seq2vec_encoder")]),e._v(".")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("multifield_dropout")])])]),e._v(" "),t("dd",[e._v("Dropout percentage to use on the output of the doc Seq2VecEncoder")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("feed_forward")])])]),e._v(" "),t("dd",[e._v("A feed forward layer applied to the encoded inputs.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("initializer")])])]),e._v(" "),t("dd",[e._v("Used to initialize the model parameters.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("regularizer")])])]),e._v(" "),t("dd",[e._v("Used to regularize the model. Passed on to :class:"),t("code",[e._v("~allennlp.models.model.Model")]),e._v(".")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("accuracy")])])]),e._v(" "),t("dd",[e._v("The accuracy you want to use. By default, we choose a categorical top-1 accuracy.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("loss_weights")])])]),e._v(" "),t("dd",[e._v("A dict with the labels and the corresponding weights.\nThese weights will be used in the CrossEntropyLoss function.")])]),e._v(" "),t("p",[e._v("Initializes internal Module state, shared by both nn.Module and ScriptModule.")])]),e._v(" "),t("h3",[e._v("Ancestors")]),e._v(" "),t("ul",{staticClass:"hlist"},[t("li",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase"}},[e._v("SequenceClassifierBase")])]),e._v(" "),t("li",[t("a",{attrs:{title:"biome.text.models.mixins.BiomeClassifierMixin",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin"}},[e._v("BiomeClassifierMixin")])]),e._v(" "),t("li",[e._v("allennlp.models.model.Model")]),e._v(" "),t("li",[e._v("torch.nn.modules.module.Module")]),e._v(" "),t("li",[e._v("allennlp.common.registrable.Registrable")]),e._v(" "),t("li",[e._v("allennlp.common.from_params.FromParams")])]),e._v(" "),t("dl",[t("h3",{attrs:{id:"biome.text.models.sequence_classifier.SequenceClassifier.forward"}},[e._v("forward "),t("Badge",{attrs:{text:"Method"}})],1),e._v(" "),t("dt",[t("div",{staticClass:"language-python extra-class"},[t("pre",{staticClass:"language-python"},[t("code",[e._v("\n"),t("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),t("span",{staticClass:"ident"},[e._v("forward")]),e._v(" ("),e._v("\n   self,\n   tokens: Dict[str, torch.Tensor],\n   label: torch.Tensor = None,\n)  -> Dict[str, torch.Tensor]\n")]),e._v("\n        ")])])]),e._v(" "),t("dd",[t("div",{staticClass:"desc"},[t("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),t("dl",[t("dt",[t("strong",[t("code",[e._v("tokens")])])]),e._v(" "),t("dd",[e._v("The input tokens.\nThe dictionary is the output of a "),t("code",[e._v("TextField.as_array()")]),e._v(". It gives names to the tensors created by\nthe "),t("code",[e._v("TokenIndexer")]),e._v("s.\nIn its most basic form, using a "),t("code",[e._v("SingleIdTokenIndexer")]),e._v(", the dictionary is composed of:\n"),t("code",[e._v('{"tokens": Tensor(batch_size, num_tokens)}')]),e._v(".\nThe keys of the dictionary are defined in the "),t("code",[e._v("model.yml")]),e._v(" input.\nThe dictionary is designed to be passed on directly to a "),t("code",[e._v("TextFieldEmbedder")]),e._v(", that has a\n"),t("code",[e._v("TokenEmbedder")]),e._v(" for each key in the dictionary (except you set "),t("code",[e._v("allow_unmatched_keys")]),e._v(" in the\n"),t("code",[e._v("TextFieldEmbedder")]),e._v(" to False) and knows how to combine different word/character representations into a\nsingle vector per token in your input.")]),e._v(" "),t("dt",[t("strong",[t("code",[e._v("label")])])]),e._v(" "),t("dd",[e._v("A torch tensor representing the sequence of integer gold class label of shape\n"),t("code",[e._v("(batch_size, num_classes)")]),e._v(".")])])])])]),e._v(" "),t("h3",[e._v("Inherited members")]),e._v(" "),t("ul",{staticClass:"hlist"},[t("li",[t("code",[t("b",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase"}},[e._v("SequenceClassifierBase")])])]),e._v(":\n"),t("ul",{staticClass:"hlist"},[t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.decode",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin.decode"}},[e._v("decode")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.extend_labels",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.extend_labels"}},[e._v("extend_labels")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.forward_tokens",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.forward_tokens"}},[e._v("forward_tokens")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.get_metrics",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin.get_metrics"}},[e._v("get_metrics")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.label_for_index",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.label_for_index"}},[e._v("label_for_index")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.n_inputs",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.n_inputs"}},[e._v("n_inputs")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.num_classes",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.num_classes"}},[e._v("num_classes")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.output_classes",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.output_classes"}},[e._v("output_classes")])])]),e._v(" "),t("li",[t("code",[t("a",{attrs:{title:"biome.text.models.sequence_classifier_base.SequenceClassifierBase.output_layer",href:"sequence_classifier_base.html#biome.text.models.sequence_classifier_base.SequenceClassifierBase.output_layer"}},[e._v("output_layer")])])])])])])])])])}),[],!1,null,null,null);s.default=n.exports}}]);