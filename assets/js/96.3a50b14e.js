(window.webpackJsonp=window.webpackJsonp||[]).push([[96],{330:function(a,e,t){"use strict";t.r(e);var s=t(33),n=Object(s.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"getting-started"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#getting-started"}},[a._v("#")]),a._v(" Getting Started")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://travis-ci.org/recognai/biome-text",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://travis-ci.org/recognai/biome-text.svg?branch=master",alt:"Build Status"}}),t("OutboundLink")],1)]),a._v(" "),t("h1",{attrs:{id:"biome-text"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#biome-text"}},[a._v("#")]),a._v(" Biome-text")]),a._v(" "),t("blockquote",[t("p",[a._v("Biome-text is a light-weight open source Natural Language Processing tool built with AllenNLP")])]),a._v(" "),t("p",[a._v("Biome-text gives you an "),t("strong",[a._v("easy path to state of the art methods")]),a._v(" for natural language processing with neural networks.")]),a._v(" "),t("h2",{attrs:{id:"features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#features"}},[a._v("#")]),a._v(" Features")]),a._v(" "),t("p",[a._v("Biome-text complements the excellent library AllenNLP by providing the following features:")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("A clean and simple "),t("strong",[a._v("user interface")]),a._v(" for exploring and understanding predictions.")])]),a._v(" "),t("li",[t("p",[a._v("Test state of the art classifiers with "),t("strong",[a._v("your own data")]),a._v(" in an easy way.")])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("Efficient dataset readers")]),a._v(" for (large) classification datasets.")])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("Modular configuration")]),a._v(" for different components such as classification dataset readers, vocabularies, models, and trainers.")])]),a._v(" "),t("li",[t("p",[a._v("Configurable "),t("strong",[a._v("text classification models")]),a._v(", including state of the art models such as Google's Bert or AllenAI's Elmo.")])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("Fully-compatible with AllenNLP")])])])]),a._v(" "),t("h2",{attrs:{id:"install"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#install"}},[a._v("#")]),a._v(" Install")]),a._v(" "),t("p",[a._v("Biome-text supports Python 3.6 and can be installed using pip and conda.")]),a._v(" "),t("h2",{attrs:{id:"pip"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pip"}},[a._v("#")]),a._v(" pip")]),a._v(" "),t("p",[a._v("For installing biome-text with pip, it is highly recommended to install packages in a virtual environment to avoid conflicts with other installations and system packages.")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("python -m venv .env\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("source")]),a._v(" .env/bin/activate\npip "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("install")]),a._v(" --upgrade pip\npip "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("install")]),a._v(" https://github.com/recognai/biome-text.git\n")])])]),t("h2",{attrs:{id:"conda"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#conda"}},[a._v("#")]),a._v(" conda")]),a._v(" "),t("p",[a._v("We provide a conda environment to install most of the package dependencies. We require you to clone this repository and run:")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("conda "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("env")]),a._v(" create -f environment.yml\nconda activate biome\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("make")]),a._v(" dev\n")])])]),t("p",[a._v("Check the installation by running:")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("biome --help\n")])])]),t("p",[a._v("You should see the available commands:")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("usage: biome [-h]  ...\n\nRun biome\n\noptional arguments:\n  -h, --help  show this help message and exit\n\nCommands:\n  \n    predict   Use a trained model to make predictions.\n    explore   Explore your data\n    serve     Run the web service.\n    learn     Make a model learn\n    vocab     Build a vocabulary\n")])])]),a._v(" "),t("h2",{attrs:{id:"working-with-biome-learn-predict-explore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#working-with-biome-learn-predict-explore"}},[a._v("#")]),a._v(" Working with Biome: Learn, predict, explore")]),a._v(" "),t("p",[a._v("Biome-text has a very similar workflow to AllenNLP, extending existing commands and defining new ones.")]),a._v(" "),t("p",[a._v("You can see the available commands and the documentation for each command adding "),t("code",[a._v("--help")]),a._v(":")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("biome --help\n")])])]),t("p",[a._v("You should see the available commands:")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("usage: biome [-h]  ...\n\nRun biome\n\noptional arguments:\n  -h, --help  show this help message and exit\n\nCommands:\n  \n    predict   Use a trained model to make predictions.\n    explore   Explore your data\n    serve     Run the web service.\n    learn     Make a model learn\n    vocab     Build a vocabulary\n")])])]),t("h3",{attrs:{id:"learn"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#learn"}},[a._v("#")]),a._v(" Learn")]),a._v(" "),t("p",[a._v("Basic training command for training models from scratch as well as fine-tuning already trained models (fine-tuning) available as binary tar.gz files.")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("biome learn --help\n")])])]),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("usage: biome learn "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-h"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--spec SPEC"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--binary BINARY"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--vocab VOCAB"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n                   --trainer TRAINER --train TRAIN "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--validation VALIDATION"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n                   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--test TEST"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" --output OUTPUT "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--workers WORKERS"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n                   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--include-package INCLUDE_PACKAGE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\nMake a model learn\n\noptional arguments:\n  -h, --help            show this "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("help")]),a._v(" message and "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("exit")]),a._v("\n  --spec SPEC           model.yml specification\n  --binary BINARY       pretrained model binary tar.gz\n  --vocab VOCAB         path to existing vocab\n  --trainer TRAINER     trainer.yml specification\n  --train TRAIN         train datasource definition\n  --validation VALIDATION\n                        validation datasource "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("source")]),a._v(" definition\n  --test TEST           "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("test")]),a._v(" datasource "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("source")]),a._v(" definition\n  --output OUTPUT       learn process generation folder\n  --workers WORKERS     Workers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" dask "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("local")]),a._v(" cluster\n  --include-package INCLUDE_PACKAGE\n")])])]),a._v(" "),t("h3",{attrs:{id:"predict"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#predict"}},[a._v("#")]),a._v(" Predict")]),a._v(" "),t("p",[a._v("Basic prediction command for using a trained model available as binary tar.gz files to make predictions with a dataset.")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("biome predict --help \n")])])]),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("usage: biome predict "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-h"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" --binary BINARY --from-source FROM_SOURCE\n                     "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--batch-size BATCH_SIZE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--cuda-device CUDA_DEVICE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n                     "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--workers WORKERS"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--include-package INCLUDE_PACKAGE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\nMake a batch prediction over input "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("test")]),a._v(" data "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("set")]),a._v("\n\noptional arguments:\n  -h, --help            show this "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("help")]),a._v(" message and "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("exit")]),a._v("\n  --binary BINARY       the archived model to "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("make")]),a._v(" predictions with\n  --from-source FROM_SOURCE\n                        datasource "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("source")]),a._v(" definition\n  --batch-size BATCH_SIZE\n                        The batch size to use "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" processing\n  --cuda-device CUDA_DEVICE\n                        "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("id")]),a._v(" of GPU to use "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("if any"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  --workers WORKERS     Workers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" dask "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("local")]),a._v(" cluster\n  --include-package INCLUDE_PACKAGE\n                        additional packages to include\n")])])]),t("h3",{attrs:{id:"explore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#explore"}},[a._v("#")]),a._v(" Explore")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("biome explore --help\n")])])]),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("usage: biome explore [-h] [--port PORT] [--include-package INCLUDE_PACKAGE]\n\nExplore your data with model annotations\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --port PORT           Listening port for application\n  --include-package INCLUDE_PACKAGE\n                        additional packages to include\n")])])]),t("h2",{attrs:{id:"motivation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#motivation"}},[a._v("#")]),a._v(" Motivation")]),a._v(" "),t("p",[a._v("At "),t("a",{attrs:{href:"http://recogn.ai",target:"_blank",rel:"noopener noreferrer"}},[a._v("Recognai"),t("OutboundLink")],1),a._v(", we love and have been working (and sometimes contributing to) libraries like "),t("a",{attrs:{href:"http://spacy.io",target:"_blank",rel:"noopener noreferrer"}},[a._v("spaCy"),t("OutboundLink")],1),a._v(", "),t("a",{attrs:{href:"http://pytorch.org",target:"_blank",rel:"noopener noreferrer"}},[a._v("PyTorch"),t("OutboundLink")],1),a._v(" and "),t("a",{attrs:{href:"https://allennlp.org",target:"_blank",rel:"noopener noreferrer"}},[a._v("AllenNLP"),t("OutboundLink")],1),a._v(" since their first releases.")]),a._v(" "),t("p",[a._v("Biome has been an internal tool for making it easier to work on use cases working with large datasets, changing requirements, evolving models, and especially for "),t("strong",[a._v("working and communicating with professionals and teams not familiarized with data science and natural language processing")]),a._v(".")]),a._v(" "),t("p",[a._v("We decided to release Biome with the hope that is useful to others, from more advanced NLP developers to people interested in getting started with these technologies.")]),a._v(" "),t("p",[a._v("Biome relies heavily in and is fully compatible with AllenNLP.")]),a._v(" "),t("p",[a._v("You can use Biome as Python package in your AllenNLP's workflows and/or use Biome extended functionalities with your AllenNLP models.\n\x3c!--")]),a._v(" "),t("h2",{attrs:{id:"contributing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#contributing"}},[a._v("#")]),a._v(" Contributing")]),a._v(" "),t("p",[a._v("If you'd like to contribute, please read our contributing guidelines. --\x3e")]),a._v(" "),t("h2",{attrs:{id:"licensing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#licensing"}},[a._v("#")]),a._v(" Licensing")]),a._v(" "),t("p",[a._v("The code in this project is licensed under Apache 2 license.")]),a._v(" "),t("h2",{attrs:{id:"setup-for-development"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#setup-for-development"}},[a._v("#")]),a._v(" Setup for development")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("$ git clone https://github.com/recognai/biome-text.git\n$ cd biome-text\n$ make dev\n")])])]),t("p",[a._v("If you do not want to install the packages required for testing, just use:")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("$ pip install -e .\n")])])])])}),[],!1,null,null,null);e.default=n.exports}}]);