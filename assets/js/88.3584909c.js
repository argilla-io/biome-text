(window.webpackJsonp=window.webpackJsonp||[]).push([[88],{336:function(e,t,i){"use strict";i.r(t);var s=i(33),a=Object(s.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"biome-text-pipelines-pipeline"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-pipelines-pipeline"}},[e._v("#")]),e._v(" biome.text.pipelines.pipeline "),i("Badge",{attrs:{text:"Module"}})],1),e._v(" "),i("dl",[i("h2",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline "),i("Badge",{attrs:{text:"Class"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[e._v("    "),i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("class")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("Pipeline")]),e._v(" (*args, **kwds)"),e._v("\n    ")])])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("This class combine the different allennlp components that make possible a "),i("code",[e._v("`"),i("a",{attrs:{title:"biome.text.pipelines.pipeline.Pipeline",href:"#biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline")])]),e._v(",\nunderstanding as a model, not only the definition of the neural network architecture,\nbut also the transformation of the input data to Instances and the evaluation of\npredictions on new data")]),e._v(" "),i("p",[e._v("The base idea is that this class contains the model and the dataset reader (as a predictor does),\nand allow operations of learning, predict and save")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("p",[e._v("model`\nThe class:~allennlp.models.Model architecture")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("reader")])])]),e._v(" "),i("dd",[e._v("The class:allennlp.data.DatasetReader")])])]),e._v(" "),i("h3",[e._v("Ancestors")]),e._v(" "),i("ul",{staticClass:"hlist"},[i("li",[e._v("typing.Generic")]),e._v(" "),i("li",[e._v("allennlp.predictors.predictor.Predictor")]),e._v(" "),i("li",[e._v("allennlp.common.registrable.Registrable")]),e._v(" "),i("li",[e._v("allennlp.common.from_params.FromParams")])]),e._v(" "),i("h3",[e._v("Subclasses")]),e._v(" "),i("ul",{staticClass:"hlist"},[i("li",[i("a",{attrs:{title:"biome.text.pipelines.biome_bimpm.BiomeBiMpmPipeline",href:"biome_bimpm.html#biome.text.pipelines.biome_bimpm.BiomeBiMpmPipeline"}},[e._v("BiomeBiMpmPipeline")])]),e._v(" "),i("li",[i("a",{attrs:{title:"biome.text.pipelines.multifield_bimpm.MultifieldBiMpmPipeline",href:"multifield_bimpm.html#biome.text.pipelines.multifield_bimpm.MultifieldBiMpmPipeline"}},[e._v("MultifieldBiMpmPipeline")])]),e._v(" "),i("li",[i("a",{attrs:{title:"biome.text.pipelines.sequence_classifier.SequenceClassifierPipeline",href:"sequence_classifier.html#biome.text.pipelines.sequence_classifier.SequenceClassifierPipeline"}},[e._v("SequenceClassifierPipeline")])]),e._v(" "),i("li",[i("a",{attrs:{title:"biome.text.pipelines.sequence_pair_classifier.SequencePairClassifierPipeline",href:"sequence_pair_classifier.html#biome.text.pipelines.sequence_pair_classifier.SequencePairClassifierPipeline"}},[e._v("SequencePairClassifierPipeline")])]),e._v(" "),i("li",[i("a",{attrs:{title:"biome.text.pipelines.similarity_classifier.SimilarityClassifierPipeline",href:"similarity_classifier.html#biome.text.pipelines.similarity_classifier.SimilarityClassifierPipeline"}},[e._v("SimilarityClassifierPipeline")])])]),e._v(" "),i("h3",[e._v("Class variables")]),e._v(" "),i("dl",[i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.PIPELINE_FIELD"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("PIPELINE_FIELD")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.ARCHITECTURE_FIELD"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("ARCHITECTURE_FIELD")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.TYPE_FIELD"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("TYPE_FIELD")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.PREDICTION_FILE_NAME"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("PREDICTION_FILE_NAME")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})])]),e._v(" "),i("dl",[i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.by_name"}},[e._v("by_name "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("by_name")]),e._v("("),i("span",[e._v("name: str) -> Type["),i("a",{attrs:{title:"biome.text.pipelines.pipeline.Pipeline",href:"#biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline")]),e._v("]")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.reader_class"}},[e._v("reader_class "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("reader_class")]),e._v("("),i("span",[e._v(") -> Type[~Reader]")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Must be implemented by subclasses")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("The class of <code>DataSourceReader</code> used in the model instance\n")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.model_class"}},[e._v("model_class "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("model_class")]),e._v("("),i("span",[e._v(") -> Type[~Architecture]")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Must be implemented by subclasses")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("The class of <code>allennlp.models.Model</code> used in the model instance\n")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.load"}},[e._v("load "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("load")]),e._v(" ("),e._v("\n   binary_path: str,\n   **kwargs,\n)  -> "),i("a",{attrs:{title:"biome.text.pipelines.pipeline.Pipeline",href:"#biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Load a model pipeline form a binary path.")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("binary_path")])])]),e._v(" "),i("dd",[e._v("Path to the binary file")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("kwargs")])])]),e._v(" "),i("dd",[e._v("Passed on to the biome.text.models.load_archive method")])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("dl",[i("dt",[i("code",[e._v("pipeline")])]),e._v(" "),i("dd",[e._v(" ")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.yaml_to_dict"}},[e._v("yaml_to_dict "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("yaml_to_dict")]),e._v("("),i("span",[e._v("filepath: str)")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.empty_pipeline"}},[e._v("empty_pipeline "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("empty_pipeline")]),e._v("("),i("span",[e._v("labels: List[str]) -> "),i("a",{attrs:{title:"biome.text.pipelines.pipeline.Pipeline",href:"#biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline")])]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Creates a dummy pipeline with labels for model layers")])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.from_config"}},[e._v("from_config "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("from_config")]),e._v(" ("),e._v("\n   path: str,\n   labels: List[str] = None,\n)  -> "),i("a",{attrs:{title:"biome.text.pipelines.pipeline.Pipeline",href:"#biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Read a "),i("code",[i("a",{attrs:{title:"biome.text.pipelines.pipeline.Pipeline",href:"#biome.text.pipelines.pipeline.Pipeline"}},[e._v("Pipeline")])]),e._v(" subclass instance by reading a configuration file")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("path")])])]),e._v(" "),i("dd",[e._v("The configuration file path")])]),e._v(" "),i("p",[e._v("labels:\nOptional. If passed, set a list of output labels for empty pipeline model")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v('An instance of <code><a title="biome.text.pipelines.pipeline.Pipeline" href="#biome.text.pipelines.pipeline.Pipeline">Pipeline</a></code> with no architecture, since the internal\n<code>allennlp.models.Model</code> needs a Vocabulary for the initialization\n')])])])])]),e._v(" "),i("h3",[e._v("Instance variables")]),e._v(" "),i("dl",[i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.reader"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("reader")]),e._v(" : "),i("a",{attrs:{title:"biome.text.dataset_readers.datasource_reader.DataSourceReader",href:"../dataset_readers/datasource_reader.html#biome.text.dataset_readers.datasource_reader.DataSourceReader"}},[e._v("DataSourceReader")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("The data reader (AKA "),i("code",[e._v("DatasetReader")]),e._v(")")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("The configured <code>DatasetReader</code>\n")])])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.model"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("model")]),e._v(" : allennlp.models.model.Model")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("The model (AKA "),i("code",[e._v("allennlp.models.Model")]),e._v(")")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("The configured <code>allennlp.models.Model</code>\n")])])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.name"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("name")]),e._v(" : str")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Get the pipeline name")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("The fully qualified pipeline class name\n")])])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.config"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("config")]),e._v(" : dict")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("A representation of reader and model in a properties defined way\nas allennlp does")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("The configuration dictionary\n")])])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.signature"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("signature")]),e._v(" : dict")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Describe de input signature for the pipeline")]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("A dict of expected inputs\n")])])])])]),e._v(" "),i("dl",[i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.init_prediction_logger"}},[e._v("init_prediction_logger "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("init_prediction_logger")]),e._v(" ("),e._v("\n   self,\n   output_dir: str,\n   max_bytes: int = 20000000,\n   backup_count: int = 20,\n) \n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Initialize the prediction logger.")]),e._v(" "),i("p",[e._v("If initialized we will log all predictions to a file called "),i("em",[e._v("predictions.json")]),e._v(" in the "),i("code",[e._v("output_folder")]),e._v(".")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("output_dir")])])]),e._v(" "),i("dd",[e._v("Path to the folder in which we create the "),i("em",[e._v("predictions.json")]),e._v(" file.")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("max_bytes")])])]),e._v(" "),i("dd",[e._v("Passed on to logging.handlers.RotatingFileHandler")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("backup_count")])])]),e._v(" "),i("dd",[e._v("Passed on to logging.handlers.RotatingFileHandler")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.predict"}},[e._v("predict "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("predict")]),e._v(" ("),e._v("\n   self,\n   **inputs,\n)  -> dict\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.predictions_to_labeled_instances"}},[e._v("predictions_to_labeled_instances "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("predictions_to_labeled_instances")]),e._v(" ("),e._v("\n   self,\n   instance: allennlp.data.instance.Instance,\n   outputs: Dict[str, numpy.ndarray],\n)  -> List[allennlp.data.instance.Instance]\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("This function takes a model's outputs for an Instance, and it labels that instance according\nto the output. For example, in classification this function labels the instance according\nto the class with the highest probability. This function is used to to compute gradients\nof what the model predicted. The return type is a list because in some tasks there are\nmultiple predictions in the output (e.g., in NER a model predicts multiple spans). In this\ncase, each instance in the returned list of Instances contains an individual\nentity prediction as the label.")])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.get_gradients"}},[e._v("get_gradients "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("get_gradients")]),e._v(" ("),e._v("\n   self,\n   instances: List[allennlp.data.instance.Instance],\n)  -> Tuple[List[Dict[str, Any]], Dict[str, Any]]\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Gets the gradients of the loss with respect to the model inputs.")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("instances")])]),e._v(" : "),i("code",[e._v("List[Instance]")])]),e._v(" "),i("dd",[e._v(" ")])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("dl",[i("dt",[i("code",[e._v("Tuple[Dict[str, Any], Dict[str, Any]]")])]),e._v(" "),i("dd",[e._v(" ")])]),e._v(" "),i("p",[e._v("The first item is a Dict of gradient entries for each input.\nThe keys have the form\n"),i("code",[e._v("{grad_input_1: ..., grad_input_2: ... }")]),e._v("\nup to the number of inputs given. The second item is the model's output.")]),e._v(" "),i("h2",{attrs:{id:"notes"}},[e._v("Notes")]),e._v(" "),i("p",[e._v("Takes a "),i("code",[e._v("JsonDict")]),e._v(" representing the inputs of the model and converts\nthem to :class:"),i("code",[e._v("~allennlp.data.instance.Instance")]),e._v("s, sends these through\nthe model :func:"),i("code",[e._v("forward")]),e._v(" function after registering hooks on the embedding\nlayer of the model. Calls :func:"),i("code",[e._v("backward")]),e._v(" on the loss and then removes the\nhooks.")])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.json_to_labeled_instances"}},[e._v("json_to_labeled_instances "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("json_to_labeled_instances")]),e._v(" ("),e._v("\n   self,\n   inputs: Dict[str, Any],\n)  -> List[allennlp.data.instance.Instance]\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Converts incoming json to a :class:"),i("code",[e._v("~allennlp.data.instance.Instance")]),e._v(",\nruns the model on the newly created instance, and adds labels to the\n:class:"),i("code",[e._v("~allennlp.data.instance.Instance")]),e._v("s given by the model's output.\nReturns")]),e._v(" "),i("hr"),e._v(" "),i("dl",[i("dt",[i("code",[e._v("List[instance]")])]),e._v(" "),i("dd",[e._v(" ")])]),e._v(" "),i("p",[e._v("A list of :class:"),i("code",[e._v("~allennlp.data.instance.Instance")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.predict_json"}},[e._v("predict_json "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("predict_json")]),e._v(" ("),e._v("\n   self,\n   inputs: Dict[str, Any],\n)  -> Union[Dict[str, Any], NoneType]\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Predict an input with the pipeline's model.")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("inputs")])])]),e._v(" "),i("dd",[e._v("The input features/tokens in form of a json dict")])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("dl",[i("dt",[i("code",[e._v("output")])]),e._v(" "),i("dd",[e._v("The model's prediction in form of a dict.\nReturns None if the input could not be transformed to an instance.")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.init_prediction_cache"}},[e._v("init_prediction_cache "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("init_prediction_cache")]),e._v(" ("),e._v("\n   self,\n   max_size,\n)  -> NoneType\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Initialize a prediction cache using the functools.lru_cache decorator")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("max_size")])])]),e._v(" "),i("dd",[e._v("Save up to max_size most recent items.")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.learn"}},[e._v("learn "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("learn")]),e._v(" ("),e._v("\n   self,\n   trainer: str,\n   train: str,\n   output: str,\n   validation: str = None,\n   test: Union[str, NoneType] = None,\n   vocab: Union[str, NoneType] = None,\n   verbose: bool = False,\n) \n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Launch a learning process for loaded model configuration.")]),e._v(" "),i("p",[e._v("Once the learn process finish, the model is ready for make predictions")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("trainer")])])]),e._v(" "),i("dd",[e._v("The trainer file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("train")])])]),e._v(" "),i("dd",[e._v("The train datasource file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("validation")])])]),e._v(" "),i("dd",[e._v("The validation datasource file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("output")])])]),e._v(" "),i("dd",[e._v("The learn output path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("vocab")])]),e._v(" : "),i("code",[e._v("Vocab")])]),e._v(" "),i("dd",[e._v("The already generated vocabulary path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("test")])]),e._v(" : "),i("code",[e._v("str")])]),e._v(" "),i("dd",[e._v("The test datasource configuration")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("verbose")])])]),e._v(" "),i("dd",[e._v("Turn on verbose logs")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.extend_labels"}},[e._v("extend_labels "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("extend_labels")]),e._v(" ("),e._v("\n   self,\n   labels: List[str],\n)  -> NoneType\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Allow extend prediction labels to pipeline")])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipelines.pipeline.Pipeline.get_output_labels"}},[e._v("get_output_labels "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("get_output_labels")]),e._v("("),i("span",[e._v("self) -> List[str]")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Output model labels")])])])])])])])}),[],!1,null,null,null);t.default=a.exports}}]);