(window.webpackJsonp=window.webpackJsonp||[]).push([[44],{381:function(e,t,i){"use strict";i.r(t);var a=i(26),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"biome-text-pipeline"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-pipeline"}},[e._v("#")]),e._v(" biome.text.pipeline "),i("Badge",{attrs:{text:"Module"}})],1),e._v(" "),i("dl",[i("h2",{attrs:{id:"biome.text.pipeline.Pipeline"}},[e._v("Pipeline "),i("Badge",{attrs:{text:"Class"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[e._v("    "),i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("class")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("Pipeline")]),e._v(" ()"),e._v("\n    ")])])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Manages NLP models configuration and actions.")]),e._v(" "),i("p",[e._v("Use "),i("code",[i("a",{attrs:{title:"biome.text.pipeline.Pipeline",href:"#biome.text.pipeline.Pipeline"}},[e._v("Pipeline")])]),e._v(" for creating new models from a configuration or loading a pre-trained model.")]),e._v(" "),i("p",[e._v("Use instantiated Pipelines for training from scratch, fine-tuning, predicting, serving, or exploring predictions.")])]),e._v(" "),i("h3",[e._v("Subclasses")]),e._v(" "),i("ul",{staticClass:"hlist"},[i("li",[e._v("biome.text.pipeline._BlankPipeline")]),e._v(" "),i("li",[e._v("biome.text.pipeline._PreTrainedPipeline")])]),e._v(" "),i("dl",[i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.from_yaml"}},[e._v("from_yaml "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("from_yaml")]),e._v(" ("),e._v("\n   path: str,\n   vocab_path: Union[str, NoneType] = None,\n)  -> "),i("a",{attrs:{title:"biome.text.pipeline.Pipeline",href:"#biome.text.pipeline.Pipeline"}},[e._v("Pipeline")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Creates a pipeline from a config yaml file path")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("path")])]),e._v(" : "),i("code",[e._v("str")])]),e._v(" "),i("dd",[e._v("The path to a YAML configuration file")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("vocab_path")])]),e._v(" : "),i("code",[e._v("Optional[str]")])]),e._v(" "),i("dd",[e._v("If provided, the pipeline vocab will be loaded from this path")])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("pipeline")])]),e._v(" : "),i("code",[i("a",{attrs:{title:"biome.text.pipeline.Pipeline",href:"#biome.text.pipeline.Pipeline"}},[e._v("Pipeline")])])]),e._v(" "),i("dd",[e._v("A configured pipeline")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.from_config"}},[e._v("from_config "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("from_config")]),e._v(" ("),e._v("\n   config: Union[str, biome.text.configuration.PipelineConfiguration],\n   vocab_path: Union[str, NoneType] = None,\n)  -> "),i("a",{attrs:{title:"biome.text.pipeline.Pipeline",href:"#biome.text.pipeline.Pipeline"}},[e._v("Pipeline")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Creates a pipeline from a "),i("code",[e._v("PipelineConfiguration")]),e._v(" object")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("config")])]),e._v(" : "),i("code",[e._v("Union[str, PipelineConfiguration]")])]),e._v(" "),i("dd",[e._v("A "),i("code",[e._v("PipelineConfiguration")]),e._v(" object or a YAML "),i("code",[e._v("str")]),e._v(" for the pipeline configuration")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("vocab_path")])]),e._v(" : "),i("code",[e._v("Optional[str]")])]),e._v(" "),i("dd",[e._v("If provided, the pipeline vocab will be loaded from this path")])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("pipeline")])]),e._v(" : "),i("code",[i("a",{attrs:{title:"biome.text.pipeline.Pipeline",href:"#biome.text.pipeline.Pipeline"}},[e._v("Pipeline")])])]),e._v(" "),i("dd",[e._v("A configured pipeline")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.from_pretrained"}},[e._v("from_pretrained "),i("Badge",{attrs:{text:"Static method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("from_pretrained")]),e._v(" ("),e._v("\n   path: str,\n   **kwargs,\n)  -> "),i("a",{attrs:{title:"biome.text.pipeline.Pipeline",href:"#biome.text.pipeline.Pipeline"}},[e._v("Pipeline")]),e._v("\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Loads a pipeline from a pre-trained pipeline from a model.tar.gz file path")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("pre",[i("code",[e._v('path: <code>str</code>\n    The path to the model.tar.gz file of a pre-trained <code><a title="biome.text.pipeline.Pipeline" href="#biome.text.pipeline.Pipeline">Pipeline</a></code>\n')])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v('pipeline: <code><a title="biome.text.pipeline.Pipeline" href="#biome.text.pipeline.Pipeline">Pipeline</a></code>\n    A configured pipeline\n')])])])])]),e._v(" "),i("h3",[e._v("Instance variables")]),e._v(" "),i("dl",[i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.name"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("name")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Gets pipeline\nname")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.inputs"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("inputs")]),e._v(" : List[str]")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Gets pipeline input field names")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.output"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("output")]),e._v(" : str")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Gets pipeline output field names")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.backbone"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("backbone")]),e._v(" : "),i("a",{attrs:{title:"biome.text.backbone.BackboneEncoder",href:"backbone.html#biome.text.backbone.BackboneEncoder"}},[e._v("BackboneEncoder")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Gets pipeline backbone encoder")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.head"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("head")]),e._v(" : "),i("a",{attrs:{title:"biome.text.modules.heads.defs.TaskHead",href:"modules/heads/defs.html#biome.text.modules.heads.defs.TaskHead"}},[e._v("TaskHead")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Gets pipeline task head")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.config"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("config")]),e._v(" : "),i("a",{attrs:{title:"biome.text.configuration.PipelineConfiguration",href:"configuration.html#biome.text.configuration.PipelineConfiguration"}},[e._v("PipelineConfiguration")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"})]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.type_name"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("type_name")]),e._v(" : str")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("The pipeline name. Equivalent to task head name")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.trainable_parameters"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("trainable_parameters")]),e._v(" : int")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Return the number of trainable parameters.")]),e._v(" "),i("p",[e._v("This number could be change before an after a training process, since trainer could fix some of them.")])])]),e._v(" "),i("dt",{attrs:{id:"biome.text.pipeline.Pipeline.trainable_parameter_names"}},[i("code",{staticClass:"name"},[e._v("var "),i("span",{staticClass:"ident"},[e._v("trainable_parameter_names")]),e._v(" : List[str]")])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Returns the name of pipeline trainable parameters")])])])]),e._v(" "),i("dl",[i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.train"}},[e._v("train "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("train")]),e._v(" ("),e._v("\n   self,\n   output: str,\n   trainer: "),i("a",{attrs:{title:"biome.text.configuration.TrainerConfiguration",href:"configuration.html#biome.text.configuration.TrainerConfiguration"}},[e._v("TrainerConfiguration")]),e._v(",\n   training: str,\n   validation: Union[str, NoneType] = None,\n   test: Union[str, NoneType] = None,\n   verbose: bool = False,\n   extend_vocab: Union[biome.text.configuration.VocabularyConfiguration, NoneType] = None,\n   restore: bool = True,\n)  -> NoneType\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Launches a training run with the specified configurations and datasources")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("output")])]),e._v(" : "),i("code",[e._v("str")])]),e._v(" "),i("dd",[e._v("The experiment output path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("trainer")])]),e._v(" : "),i("code",[e._v("str")])]),e._v(" "),i("dd",[e._v("The trainer file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("training")])]),e._v(" : "),i("code",[e._v("str")])]),e._v(" "),i("dd",[e._v("The train datasource file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("validation")])]),e._v(" : "),i("code",[e._v("Optional[str]")])]),e._v(" "),i("dd",[e._v("The validation datasource file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("test")])]),e._v(" : "),i("code",[e._v("Optional[str]")])]),e._v(" "),i("dd",[e._v("The test datasource file path")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("verbose")])]),e._v(" : "),i("code",[e._v("bool")])]),e._v(" "),i("dd",[e._v("Turn on verbose logs")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("extend_vocab")])]),e._v(" : "),i("code",[e._v("Optional[VocabularyConfiguration]")])]),e._v(" "),i("dd",[e._v("Extends vocab tokens with provided configuration")]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("restore")])]),e._v(" : "),i("code",[e._v("bool")])]),e._v(" "),i("dd",[e._v("If enabled, tries to read previous training status from output folder and\ncontinues training process from it")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.predict"}},[e._v("predict "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("predict")]),e._v(" ("),e._v("\n   self,\n   *args,\n   **kwargs,\n)  -> Dict[str, numpy.ndarray]\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Predicts over some input data with current state of the model")]),e._v(" "),i("h1",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("pre",[i("code",[e._v("args: `*args`\nkwargs: `**kwargs`\n")])]),e._v(" "),i("h1",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("predictions: <code>Dict\\[str, numpy.ndarray]</code>\n    A dictionary containing the predictions and additional information\n")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.explain"}},[e._v("explain "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("explain")]),e._v(" ("),e._v("\n   self,\n   *args,\n   **kwargs,\n)  -> Dict[str, Any]\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Predicts over some input data with current state of the model and provides explanations of token importance.")]),e._v(" "),i("h1",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("pre",[i("code",[e._v("args: `*args`\nkwargs: `**kwargs`\n")])]),e._v(" "),i("h1",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v("predictions: <code>Dict\\[str, numpy.ndarray]</code>\n    A dictionary containing the predictions with token importance calculated using IntegratedGradients\n")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.save_vocab"}},[e._v("save_vocab "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("save_vocab")]),e._v(" ("),e._v("\n   self,\n   path: str,\n)  -> NoneType\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Save the pipeline vocabulary into a path")])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.explore"}},[e._v("explore "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("explore")]),e._v(" ("),e._v("\n   self,\n   ds_path: str,\n   explore_id: Union[str, NoneType] = None,\n   es_host: Union[str, NoneType] = None,\n   batch_size: int = 500,\n   prediction_cache_size: int = 0,\n   explain: bool = False,\n   force_delete: bool = True,\n   **metadata,\n)  -> dask.dataframe.core.DataFrame\n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Launches Explore UI for a given datasource with current model")]),e._v(" "),i("p",[e._v("Running this method inside a an "),i("code",[e._v("IPython")]),e._v(" notebook will try to render the UI directly in the notebook.")]),e._v(" "),i("p",[e._v("Running this outside a notebook will try to launch the standalone web application.")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("pre",[i("code",[e._v("ds_path: <code>str</code>\n    The path to the configuration of a datasource\nexplore_id: <code>Optional\\[str]</code>\n    A name or id for this explore run, useful for running and keep track of several explorations\nes_host: <code>Optional\\[str]</code>\n    The URL to the Elasticsearch host for indexing predictions (default is `localhost:9200`)\nbatch_size: <code>int</code>\n    The batch size for indexing predictions (default is `500)\nprediction_cache_size: <code>int</code>\n    The size of the cache for caching predictions (default is `0)\nexplain: <code>bool</code>\n    Whether to extract and return explanations of token importance (default is <code>False</code>)\nforce_delete: <code>bool</code>\n    Deletes exploration with the same <code>explore\\_id</code> before indexing the new explore items (default is `True)\n")])]),e._v(" "),i("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),i("pre",[i("code",[e._v('pipeline: <code><a title="biome.text.pipeline.Pipeline" href="#biome.text.pipeline.Pipeline">Pipeline</a></code>\n    A configured pipeline\n')])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.serve"}},[e._v("serve "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("serve")]),e._v(" ("),e._v("\n   self,\n   port: int = 9998,\n) \n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Launches a REST prediction service with current model in a specified port (default is `9998)")]),e._v(" "),i("h1",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("pre",[i("code",[e._v("port: <code>int</code>\n    The port to make available the prediction service\n")])])])]),e._v(" "),i("h3",{attrs:{id:"biome.text.pipeline.Pipeline.set_head"}},[e._v("set_head "),i("Badge",{attrs:{text:"Method"}})],1),e._v(" "),i("dt",[i("div",{staticClass:"language-python extra-class"},[i("pre",{staticClass:"language-python"},[i("code",[e._v("\n"),i("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),i("span",{staticClass:"ident"},[e._v("set_head")]),e._v(" ("),e._v("\n   self,\n   type: Type["),i("a",{attrs:{title:"biome.text.modules.heads.defs.TaskHead",href:"modules/heads/defs.html#biome.text.modules.heads.defs.TaskHead"}},[e._v("TaskHead")]),e._v("],\n   **params,\n) \n")]),e._v("\n        ")])])]),e._v(" "),i("dd",[i("div",{staticClass:"desc"},[i("p",[e._v("Sets a new task head for the pipeline")]),e._v(" "),i("p",[e._v("Use this to reuse the weights and config of a pre-trained model (e.g., language model) for a new task.")]),e._v(" "),i("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),i("dl",[i("dt",[i("strong",[i("code",[e._v("type")])]),e._v(" : "),i("code",[e._v("Type[TaskHead]")])]),e._v(" "),i("dd",[e._v("The "),i("code",[e._v("TaskHead")]),e._v(" class to be set for the pipeline (e.g., "),i("code",[e._v("TextClassification")])]),e._v(" "),i("dt",[i("strong",[i("code",[e._v("params")])]),e._v(" : "),i("code",[e._v("**kwargs")])]),e._v(" "),i("dd",[e._v("The "),i("code",[e._v("TaskHead")]),e._v(" specific parameters (e.g., classification head needs a "),i("code",[e._v("pooler")]),e._v(" layer)")])])])])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);