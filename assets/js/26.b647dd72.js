(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{399:function(e,t,a){"use strict";a.r(t);var s=a(26),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"biome-text-featurizer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-featurizer"}},[e._v("#")]),e._v(" biome.text.featurizer "),a("Badge",{attrs:{text:"Module"}})],1),e._v(" "),a("div"),e._v(" "),a("div"),e._v(" "),a("pre",{staticClass:"title"},[a("h2",{attrs:{id:"inputfeaturizer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#inputfeaturizer"}},[e._v("#")]),e._v(" InputFeaturizer "),a("Badge",{attrs:{text:"Class"}})],1),e._v("\n")]),e._v(" "),a("pre",{staticClass:"language-python"},[e._v("            "),a("code",[e._v("\n              "),a("span",{staticClass:"token keyword"},[e._v("class")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("InputFeaturizer")]),e._v(" ("),e._v("\n                  "),a("span",[e._v("words: Union[Dict[str, Any], NoneType] = None")]),a("span",[e._v(",")]),e._v("\n                  "),a("span",[e._v("chars: Union[Dict[str, Any], NoneType] = None")]),a("span",[e._v(",")]),e._v("\n                  "),a("span",[e._v("**kwargs: Dict[str, Dict[str, Any]]")]),a("span",[e._v(",")]),e._v("\n              "),a("span",[e._v(")")]),e._v("\n            ")]),e._v("\n          ")]),e._v(" "),a("p",[e._v("Transforms input text (words and/or characters) into indexes and embedding vectors.")]),e._v(" "),a("p",[e._v("This class defines two input features, words and chars for embeddings at word and character level respectively.")]),e._v(" "),a("p",[e._v("You can provide additional features by manually specify "),a("code",[e._v("indexer")]),e._v(" and "),a("code",[e._v("embedder")]),e._v(" configurations within each\ninput feature.")]),e._v(" "),a("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),a("dl",[a("dt",[a("strong",[a("code",[e._v("words")])]),e._v(" : "),a("code",[e._v("Dict[str, Any]")])]),e._v(" "),a("dd",[e._v("Dictionary defining how to index and embed words")]),e._v(" "),a("dt",[a("strong",[a("code",[e._v("chars")])]),e._v(" : "),a("code",[e._v("Dict[str, Any]")])]),e._v(" "),a("dd",[e._v("Dictionary defining how to encode and embed characters")])]),e._v(" "),a("p",[e._v("kwargs :\nAdditional params for setting up the features")]),e._v(" "),a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"class-variables"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-variables"}},[e._v("#")]),e._v(" Class variables")]),e._v("\n")]),e._v(" "),a("dl",[a("dt",{attrs:{id:"biome.text.featurizer.InputFeaturizer.WORDS"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("WORDS")])])]),e._v(" "),a("dd"),e._v(" "),a("dt",{attrs:{id:"biome.text.featurizer.InputFeaturizer.CHARS"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("CHARS")])])]),e._v(" "),a("dd")]),e._v(" "),a("dl",[a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"from-params"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#from-params"}},[e._v("#")]),e._v(" from_params "),a("Badge",{attrs:{text:"Static method"}})],1),e._v("\n")]),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[e._v("          "),a("code",[e._v("\n          "),a("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("from_params")]),e._v("("),a("span",[e._v("params: allennlp.common.params.Params) -> "),a("a",{attrs:{title:"biome.text.featurizer.InputFeaturizer",href:"#biome.text.featurizer.InputFeaturizer"}},[e._v("InputFeaturizer")])]),e._v("\n          ")]),e._v("\n        ")])])]),e._v(" "),a("dd",[a("p",[e._v("Loads featurizer from "),a("code",[e._v("allennlp.Params")])]),e._v(" "),a("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),a("dl",[a("dt",[a("strong",[a("code",[e._v("params")])]),e._v(" : "),a("code",[e._v("Params")])]),e._v(" "),a("dd",[e._v("Params for the featurizer configuration")])]),e._v(" "),a("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),a("p",[e._v("An instance of "),a("code",[a("a",{attrs:{title:"biome.text.featurizer.InputFeaturizer",href:"#biome.text.featurizer.InputFeaturizer"}},[e._v("InputFeaturizer")])])])])]),e._v(" "),a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"instance-variables"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#instance-variables"}},[e._v("#")]),e._v(" Instance variables")]),e._v("\n")]),e._v(" "),a("dl",[a("dt",{attrs:{id:"biome.text.featurizer.InputFeaturizer.config"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("config")])])]),e._v(" "),a("dd",[a("p",[e._v("The featurizer configuration")])]),e._v(" "),a("dt",{attrs:{id:"biome.text.featurizer.InputFeaturizer.feature_keys"}},[a("code",{staticClass:"name"},[e._v("var "),a("span",{staticClass:"ident"},[e._v("feature_keys")])])]),e._v(" "),a("dd",[a("p",[e._v('The configured feature names ("words", "chars", …)')])])]),e._v(" "),a("dl",[a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"build-features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#build-features"}},[e._v("#")]),e._v(" build_features "),a("Badge",{attrs:{text:"Method"}})],1),e._v("\n")]),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[e._v("          "),a("code",[e._v("\n          "),a("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("build_features")]),e._v("("),a("span",[e._v("self) -> Dict[str, allennlp.data.token_indexers.token_indexer.TokenIndexer]")]),e._v("\n          ")]),e._v("\n        ")])])]),e._v(" "),a("dd",[a("p",[e._v("Builds configured token indexers features as allennlp token indexers.")]),e._v(" "),a("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),a("dl",[a("dt",[a("code",[e._v("An dictionary defining the token indexers")]),e._v(" of "),a("code",[e._v("the featurizer")])]),e._v(" "),a("dd",[e._v(" ")])])]),e._v(" "),a("pre",{staticClass:"title"},[a("h3",{attrs:{id:"build-embedder"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#build-embedder"}},[e._v("#")]),e._v(" build_embedder "),a("Badge",{attrs:{text:"Method"}})],1),e._v("\n")]),e._v(" "),a("dt",[a("div",{staticClass:"language-python extra-class"},[a("pre",{staticClass:"language-python"},[e._v("          "),a("code",[e._v("\n          "),a("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),a("span",{staticClass:"ident"},[e._v("build_embedder")]),e._v(" ("),e._v("\n            self,\n            vocab: allennlp.data.vocabulary.Vocabulary,\n          )  -> allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder\n          ")]),e._v("\n        ")])])]),e._v(" "),a("dd",[a("p",[e._v("Builds a "),a("code",[e._v("TextFieldEmbedder")]),e._v(" from configured embedding features")]),e._v(" "),a("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),a("dl",[a("dt",[a("strong",[a("code",[e._v("vocab")])]),e._v(" : "),a("code",[e._v("Vocabulary")])]),e._v(" "),a("dd",[e._v("Vocabulary object to be used by the embedding layers")])]),e._v(" "),a("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),a("p",[e._v("A "),a("code",[e._v("TextFieldEmbedder")])])])])])}),[],!1,null,null,null);t.default=r.exports}}]);