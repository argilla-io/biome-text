(window.webpackJsonp=window.webpackJsonp||[]).push([[67],{408:function(e,t,o){"use strict";o.r(t);var i=o(33),a=Object(i.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"biome-text-models-biome-bimpm"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#biome-text-models-biome-bimpm"}},[e._v("#")]),e._v(" biome.text.models.biome_bimpm "),o("Badge",{attrs:{text:"Module"}})],1),e._v(" "),o("dl",[o("h2",{attrs:{id:"biome.text.models.biome_bimpm.BiomeBiMpm"}},[e._v("BiomeBiMpm "),o("Badge",{attrs:{text:"Class"}})],1),e._v(" "),o("dt",[o("div",{staticClass:"language-python extra-class"},[o("pre",{staticClass:"language-python"},[e._v("    "),o("code",[e._v("\n"),o("span",{staticClass:"token keyword"},[e._v("class")]),e._v(" "),o("span",{staticClass:"ident"},[e._v("BiomeBiMpm")]),e._v(" ("),e._v("\n    "),o("span",[e._v("vocab: allennlp.data.vocabulary.Vocabulary")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("text_field_embedder: allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("matcher_word: allennlp.modules.bimpm_matching.BiMpmMatching")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("encoder1: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("matcher_forward1: allennlp.modules.bimpm_matching.BiMpmMatching")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("matcher_backward1: allennlp.modules.bimpm_matching.BiMpmMatching")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("encoder2: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("matcher_forward2: allennlp.modules.bimpm_matching.BiMpmMatching")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("matcher_backward2: allennlp.modules.bimpm_matching.BiMpmMatching")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("aggregator: allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("classifier_feedforward: allennlp.modules.feedforward.FeedForward")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("dropout: float = 0.1")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("initializer: allennlp.nn.initializers.InitializerApplicator = <allennlp.nn.initializers.InitializerApplicator object>")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("regularizer: Union[allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator, NoneType] = None")]),o("span",[e._v(",")]),e._v("\n    "),o("span",[e._v("accuracy: Union[allennlp.training.metrics.categorical_accuracy.CategoricalAccuracy, NoneType] = None")]),o("span",[e._v(",")]),e._v("\n"),o("span",[e._v(")")]),e._v("\n    ")])])])]),e._v(" "),o("dd",[o("div",{staticClass:"desc"},[o("p",[e._v("This "),o("code",[e._v("Model")]),e._v(" implements BiMPM model described in "),o("code",[e._v("Bilateral Multi-Perspective Matching\nfor Natural Language Sentences <https://arxiv.org/abs/1702.03814>")]),o("em",[e._v(" by Zhiguo Wang et al., 2017.\nAlso please refer to the "),o("code",[e._v("TensorFlow implementation <https://github.com/zhiguowang/BiMPM/>")])]),e._v(" and\n"),o("code",[e._v("PyTorch implementation <https://github.com/galsang/BIMPM-pytorch>")]),e._v("_.")]),e._v(" "),o("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),o("dl",[o("dt",[o("strong",[o("code",[e._v("vocab")])]),e._v(" : "),o("code",[e._v("Vocabulary")])]),e._v(" "),o("dd",[e._v(" ")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("text_field_embedder")])]),e._v(" : "),o("code",[e._v("TextFieldEmbedder")])]),e._v(" "),o("dd",[e._v("Used to embed the "),o("code",[e._v("premise")]),e._v(" and "),o("code",[e._v("hypothesis")]),e._v(" "),o("code",[e._v("TextFields")]),e._v(" we get as input to the\nmodel.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("matcher_word")])]),e._v(" : "),o("code",[e._v("BiMpmMatching")])]),e._v(" "),o("dd",[e._v("BiMPM matching on the output of word embeddings of premise and hypothesis.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("encoder1")])]),e._v(" : "),o("code",[e._v("Seq2SeqEncoder")])]),e._v(" "),o("dd",[e._v("First encoder layer for the premise and hypothesis")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("matcher_forward1")])]),e._v(" : "),o("code",[e._v("BiMPMMatching")])]),e._v(" "),o("dd",[e._v("BiMPM matching for the forward output of first encoder layer")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("matcher_backward1")])]),e._v(" : "),o("code",[e._v("BiMPMMatching")])]),e._v(" "),o("dd",[e._v("BiMPM matching for the backward output of first encoder layer")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("encoder2")])]),e._v(" : "),o("code",[e._v("Seq2SeqEncoder")])]),e._v(" "),o("dd",[e._v("Second encoder layer for the premise and hypothesis")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("matcher_forward2")])]),e._v(" : "),o("code",[e._v("BiMPMMatching")])]),e._v(" "),o("dd",[e._v("BiMPM matching for the forward output of second encoder layer")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("matcher_backward2")])]),e._v(" : "),o("code",[e._v("BiMPMMatching")])]),e._v(" "),o("dd",[e._v("BiMPM matching for the backward output of second encoder layer")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("aggregator")])]),e._v(" : "),o("code",[e._v("Seq2VecEncoder")])]),e._v(" "),o("dd",[e._v("Aggregator of all BiMPM matching vectors")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("classifier_feedforward")])]),e._v(" : "),o("code",[e._v("FeedForward")])]),e._v(" "),o("dd",[e._v("Fully connected layers for classification.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("dropout")])]),e._v(" : "),o("code",[e._v("float")]),e._v(", optional "),o("code",[e._v("(default=0.1)")])]),e._v(" "),o("dd",[e._v("Dropout percentage to use.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("initializer")])]),e._v(" : "),o("code",[e._v("InitializerApplicator")]),e._v(", optional "),o("code",[e._v("(default=``InitializerApplicator()``)")])]),e._v(" "),o("dd",[e._v("If provided, will be used to initialize the model parameters.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("regularizer")])]),e._v(" : "),o("code",[e._v("RegularizerApplicator")]),e._v(", optional "),o("code",[e._v("(default=``None``)")])]),e._v(" "),o("dd",[e._v("If provided, will be used to calculate the regularization penalty during training.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("accuracy")])])]),e._v(" "),o("dd",[e._v("The accuracy you want to use. By default, we choose a categorical top-1 accuracy.")])]),e._v(" "),o("p",[e._v("Initializes internal Module state, shared by both nn.Module and ScriptModule.")])]),e._v(" "),o("h3",[e._v("Ancestors")]),e._v(" "),o("ul",{staticClass:"hlist"},[o("li",[o("a",{attrs:{title:"biome.text.models.mixins.BiomeClassifierMixin",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin"}},[e._v("BiomeClassifierMixin")])]),e._v(" "),o("li",[e._v("allennlp.models.bimpm.BiMpm")]),e._v(" "),o("li",[e._v("allennlp.models.model.Model")]),e._v(" "),o("li",[e._v("torch.nn.modules.module.Module")]),e._v(" "),o("li",[e._v("allennlp.common.registrable.Registrable")]),e._v(" "),o("li",[e._v("allennlp.common.from_params.FromParams")])]),e._v(" "),o("dl",[o("h3",{attrs:{id:"biome.text.models.biome_bimpm.BiomeBiMpm.forward"}},[e._v("forward "),o("Badge",{attrs:{text:"Method"}})],1),e._v(" "),o("dt",[o("div",{staticClass:"language-python extra-class"},[o("pre",{staticClass:"language-python"},[o("code",[e._v("\n"),o("span",{staticClass:"token keyword"},[e._v("def")]),e._v(" "),o("span",{staticClass:"ident"},[e._v("forward")]),e._v(" ("),e._v("\n   self,\n   record1: Dict[str, torch.LongTensor],\n   record2: Dict[str, torch.LongTensor],\n   label: torch.Tensor = None,\n)  -> Dict[str, torch.Tensor]\n")]),e._v("\n        ")])])]),e._v(" "),o("dd",[o("div",{staticClass:"desc"},[o("h2",{attrs:{id:"parameters"}},[e._v("Parameters")]),e._v(" "),o("dl",[o("dt",[o("strong",[o("code",[e._v("premise")])]),e._v(" : "),o("code",[e._v("Dict[str, torch.LongTensor]")])]),e._v(" "),o("dd",[e._v("The premise from a "),o("code",[e._v("TextField")])]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("hypothesis")])]),e._v(" : "),o("code",[e._v("Dict[str, torch.LongTensor]")])]),e._v(" "),o("dd",[e._v("The hypothesis from a "),o("code",[e._v("TextField")])]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("label")])]),e._v(" : "),o("code",[e._v("torch.LongTensor")]),e._v(", optional "),o("code",[e._v("(default = None)")])]),e._v(" "),o("dd",[e._v("The label for the pair of the premise and the hypothesis")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("metadata")])]),e._v(" : "),o("code",[e._v("List[Dict[str, Any]]")]),e._v(", optional"),o("code",[e._v(", (default = None)")])]),e._v(" "),o("dd",[e._v("Additional information about the pair")])]),e._v(" "),o("h2",{attrs:{id:"returns"}},[e._v("Returns")]),e._v(" "),o("dl",[o("dt",[o("code",[e._v("An output dictionary consisting of:")])]),e._v(" "),o("dd",[e._v(" ")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("logits")])]),e._v(" : "),o("code",[e._v("torch.FloatTensor")])]),e._v(" "),o("dd",[e._v("A tensor of shape "),o("code",[e._v("(batch_size, num_labels)")]),e._v(" representing unnormalised log\nprobabilities of the entailment label.")]),e._v(" "),o("dt",[o("strong",[o("code",[e._v("loss")])]),e._v(" : "),o("code",[e._v("torch.FloatTensor")]),e._v(", optional")]),e._v(" "),o("dd",[e._v("A scalar loss to be optimised.")])])])])]),e._v(" "),o("h3",[e._v("Inherited members")]),e._v(" "),o("ul",{staticClass:"hlist"},[o("li",[o("code",[o("b",[o("a",{attrs:{title:"biome.text.models.mixins.BiomeClassifierMixin",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin"}},[e._v("BiomeClassifierMixin")])])]),e._v(":\n"),o("ul",{staticClass:"hlist"},[o("li",[o("code",[o("a",{attrs:{title:"biome.text.models.mixins.BiomeClassifierMixin.decode",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin.decode"}},[e._v("decode")])])]),e._v(" "),o("li",[o("code",[o("a",{attrs:{title:"biome.text.models.mixins.BiomeClassifierMixin.get_metrics",href:"mixins.html#biome.text.models.mixins.BiomeClassifierMixin.get_metrics"}},[e._v("get_metrics")])])])])])])])])])}),[],!1,null,null,null);t.default=a.exports}}]);